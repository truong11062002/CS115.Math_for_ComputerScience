{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20522087_NguyenNhatTruong.ipynb","provenance":[],"toc_visible":true,"mount_file_id":"1fVeLFyMXiG9Vmr_AzUCAZostwp41LDHJ","authorship_tag":"ABX9TyN6uyois5AZ5LJLDLq8iscs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# FashionMNIST using MLP model"],"metadata":{"id":"bO2Z_n0Hggtj"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rjpvDVq6eMis","executionInfo":{"status":"ok","timestamp":1639275672255,"user_tz":-420,"elapsed":9506,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"outputId":"e82cd937-9500-4cc0-cca1-526655474738"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## Import nescessary libraries"],"metadata":{"id":"fDMsUwR8UWCG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"E8EgC1PPd87u"},"outputs":[],"source":["# Import nescessary libraries\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Build model\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# Training strategy\n","import torch.optim as optim\n","# Split data\n","from torch.utils.data import DataLoader\n","# Load data\n","import torchvision.datasets as datasets\n","# Data preprocessing\n","import torchvision.transforms as transforms"]},{"cell_type":"markdown","source":["## Check 'CPU' or 'GPU'"],"metadata":{"id":"tLqeT1kKUcsI"}},{"cell_type":"code","source":["# Check whether we are using 'GPU' or 'CPU'\n","device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Zy8Ez6_ebco","executionInfo":{"status":"ok","timestamp":1639275677154,"user_tz":-420,"elapsed":333,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"outputId":"279152ee-e848-42c5-86af-7d6c2dccafa3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["# Setup for getting the reproducible results\n","\n","random.seed(1)\n","np.random.seed(1)\n","torch.manual_seed(1)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"],"metadata":{"id":"Baf0WEOCebWt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# USE FashionMNIST DATASET\n","# setup hyperparameters\n","input_size = 784 #  1*28*28\n","n_classes = 10 # 10 digits 0,...,9\n","learning_rate = 0.001 # learning rate on gradient descent\n","batch_size = 64 # the number of samples in each batch\n","n_epochs = 50 # the number of training epochs"],"metadata":{"id":"ScOnePboebQs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prepare FashionMNIST dataset"],"metadata":{"id":"9KNXudPcUr_m"}},{"cell_type":"code","source":["# LOAD data from Google Drive\n","# Load 'FashionMNIST' dataset\n","train_dataset = datasets.FashionMNIST(root='/content/drive/MyDrive/10. Toán cho KHMT/datasets' , train =True,\n","                              transform=transforms.ToTensor(), download=True)\n","train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,shuffle=True)\n","test_dataset = datasets.FashionMNIST(root='/content/drive/MyDrive/10. Toán cho KHMT/datasets' ,train=False,transform=transforms.ToTensor(),\n","                              download=True)\n","test_loader = DataLoader(dataset= test_dataset, batch_size=batch_size, shuffle=False)\n"],"metadata":{"id":"mpAciWOSebEs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Show an image example in training set\n","image, label = train_dataset[0]\n","plt.imshow(image.squeeze(), cmap='gray')\n","print(label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284},"id":"l_ksdegfjd1u","executionInfo":{"status":"ok","timestamp":1639275887611,"user_tz":-420,"elapsed":354,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"outputId":"76de8b63-a47c-4d3c-ee8c-281dd48bdd91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["9\n"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAR1klEQVR4nO3db2yVdZYH8O+xgNqCBaxA+RPBESOTjVvWikbRjI4Q9IUwanB4scGo24kZk5lkTNa4L8bEFxLdmcm+IJN01AyzzjqZZCBi/DcMmcTdFEcqYdtKd0ZACK2lBUFoS6EUzr7og+lgn3Pqfe69z5Xz/SSk7T393fvrvf1yb+95fs9PVBVEdOm7LO8JEFF5MOxEQTDsREEw7ERBMOxEQUwq542JCN/6JyoxVZXxLs/0zC4iq0TkryKyV0SeyXJdRFRaUmifXUSqAPwNwAoAXQB2AlinqnuMMXxmJyqxUjyzLwOwV1X3q+owgN8BWJ3h+oiohLKEfR6AQ2O+7kou+zsi0iQirSLSmuG2iCijkr9Bp6rNAJoBvownylOWZ/ZuAAvGfD0/uYyIKlCWsO8EsFhEFonIFADfB7C1ONMiomIr+GW8qo6IyFMA3gNQBeBVVf24aDMjoqIquPVW0I3xb3aikivJQTVE9M3BsBMFwbATBcGwEwXBsBMFwbATBcGwEwXBsBMFwbATBcGwEwXBsBMFwbATBcGwEwVR1lNJU/mJjLsA6ktZVz1OmzbNrC9fvjy19s4772S6be9nq6qqSq2NjIxkuu2svLlbCn3M+MxOFATDThQEw04UBMNOFATDThQEw04UBMNOFAT77Je4yy6z/z8/d+6cWb/++uvN+hNPPGHWh4aGUmuDg4Pm2NOnT5v1Dz/80Kxn6aV7fXDvfvXGZ5mbdfyA9XjymZ0oCIadKAiGnSgIhp0oCIadKAiGnSgIhp0oCPbZL3FWTxbw++z33HOPWb/33nvNeldXV2rt8ssvN8dWV1eb9RUrVpj1l19+ObXW29trjvXWjHv3m2fq1KmptfPnz5tjT506VdBtZgq7iBwA0A/gHIARVW3Mcn1EVDrFeGa/W1WPFuF6iKiE+Dc7URBZw64A/igiH4lI03jfICJNItIqIq0Zb4uIMsj6Mn65qnaLyCwA20Tk/1T1/bHfoKrNAJoBQESynd2QiAqW6ZldVbuTj30AtgBYVoxJEVHxFRx2EakRkWkXPgewEkBHsSZGRMWV5WX8bABbknW7kwD8l6q+W5RZUdEMDw9nGn/LLbeY9YULF5p1q8/vrQl/7733zPrSpUvN+osvvphaa22130Jqb283652dnWZ92TL7Ra51v7a0tJhjd+zYkVobGBhIrRUcdlXdD+AfCx1PROXF1htREAw7URAMO1EQDDtREAw7URCSdcver3VjPIKuJKzTFnuPr7dM1GpfAcD06dPN+tmzZ1Nr3lJOz86dO8363r17U2tZW5L19fVm3fq5AXvuDz/8sDl248aNqbXW1lacPHly3F8IPrMTBcGwEwXBsBMFwbATBcGwEwXBsBMFwbATBcE+ewXwtvfNwnt8P/jgA7PuLWH1WD+bt21x1l64teWz1+PftWuXWbd6+ID/s61atSq1dt1115lj582bZ9ZVlX12osgYdqIgGHaiIBh2oiAYdqIgGHaiIBh2oiC4ZXMFKOexDhc7fvy4WffWbQ8NDZl1a1vmSZPsXz9rW2PA7qMDwJVXXpla8/rsd955p1m//fbbzbp3muxZs2al1t59tzRnZOczO1EQDDtREAw7URAMO1EQDDtREAw7URAMO1EQ7LMHV11dbda9frFXP3XqVGrtxIkT5tjPP//crHtr7a3jF7xzCHg/l3e/nTt3zqxbff4FCxaYYwvlPrOLyKsi0iciHWMumyki20Tkk+TjjJLMjoiKZiIv438N4OLTajwDYLuqLgawPfmaiCqYG3ZVfR/AsYsuXg1gU/L5JgBrijwvIiqyQv9mn62qPcnnhwHMTvtGEWkC0FTg7RBRkWR+g05V1TqRpKo2A2gGeMJJojwV2nrrFZF6AEg+9hVvSkRUCoWGfSuA9cnn6wG8UZzpEFGpuC/jReR1AN8BUCciXQB+CmADgN+LyOMADgJYW8pJXuqy9nytnq63Jnzu3Llm/cyZM5nq1np277zwVo8e8PeGt/r0Xp98ypQpZr2/v9+s19bWmvW2trbUmveYNTY2ptb27NmTWnPDrqrrUkrf9cYSUeXg4bJEQTDsREEw7ERBMOxEQTDsREFwiWsF8E4lXVVVZdat1tsjjzxijp0zZ45ZP3LkiFm3TtcM2Es5a2pqzLHeUk+vdWe1/c6ePWuO9U5z7f3cV199tVnfuHFjaq2hocEca83NauPymZ0oCIadKAiGnSgIhp0oCIadKAiGnSgIhp0oCCnndsE8U834vJ7uyMhIwdd96623mvW33nrLrHtbMmc5BmDatGnmWG9LZu9U05MnTy6oBvjHAHhbXXusn+2ll14yx7722mtmXVXHbbbzmZ0oCIadKAiGnSgIhp0oCIadKAiGnSgIhp0oiG/UenZrra7X7/VOx+ydztla/2yt2Z6ILH10z9tvv23WBwcHzbrXZ/dOuWwdx+Gtlfce0yuuuMKse2vWs4z1HnNv7jfddFNqzdvKulB8ZicKgmEnCoJhJwqCYScKgmEnCoJhJwqCYScKoqL67FnWRpeyV11qd911l1l/6KGHzPodd9yRWvO2PfbWhHt9dG8tvvWYeXPzfh+s88IDdh/eO4+DNzePd78NDAyk1h588EFz7JtvvlnQnNxndhF5VUT6RKRjzGXPiUi3iOxO/t1f0K0TUdlM5GX8rwGsGufyX6hqQ/LPPkyLiHLnhl1V3wdwrAxzIaISyvIG3VMi0pa8zJ+R9k0i0iQirSLSmuG2iCijQsP+SwDfAtAAoAfAz9K+UVWbVbVRVRsLvC0iKoKCwq6qvap6TlXPA/gVgGXFnRYRFVtBYReR+jFffg9AR9r3ElFlcM8bLyKvA/gOgDoAvQB+mnzdAEABHADwA1XtcW8sx/PGz5w506zPnTvXrC9evLjgsV7f9IYbbjDrZ86cMevWWn1vXba3z/hnn31m1r3zr1v9Zm8Pc2//9erqarPe0tKSWps6dao51jv2wVvP7q1Jt+633t5ec+ySJUvMetp5492DalR13TgXv+KNI6LKwsNliYJg2ImCYNiJgmDYiYJg2ImCqKgtm2+77TZz/PPPP59au+aaa8yx06dPN+vWUkzAXm75xRdfmGO95bdeC8lrQVmnwfZOBd3Z2WnW165da9ZbW+2joK1tmWfMSD3KGgCwcOFCs+7Zv39/as3bLrq/v9+se0tgvZam1fq76qqrzLHe7wu3bCYKjmEnCoJhJwqCYScKgmEnCoJhJwqCYScKoux9dqtfvWPHDnN8fX19as3rk3v1LKcO9k557PW6s6qtrU2t1dXVmWMfffRRs75y5Uqz/uSTT5p1a4ns6dOnzbGffvqpWbf66IC9LDnr8lpvaa/Xx7fGe8tnr732WrPOPjtRcAw7URAMO1EQDDtREAw7URAMO1EQDDtREGXts9fV1ekDDzyQWt+wYYM5ft++fak179TAXt3b/tfi9VytPjgAHDp0yKx7p3O21vJbp5kGgDlz5pj1NWvWmHVrW2TAXpPuPSY333xzprr1s3t9dO9+87Zk9ljnIPB+n6zzPhw+fBjDw8PssxNFxrATBcGwEwXBsBMFwbATBcGwEwXBsBMF4e7iWkwjIyPo6+tLrXv9ZmuNsLetsXfdXs/X6qt65/k+duyYWT948KBZ9+ZmrZf31ox757TfsmWLWW9vbzfrVp/d20bb64V75+u3tqv2fm5vTbnXC/fGW312r4dvbfFt3SfuM7uILBCRP4vIHhH5WER+lFw+U0S2icgnyUf7jP9ElKuJvIwfAfATVf02gNsA/FBEvg3gGQDbVXUxgO3J10RUodywq2qPqu5KPu8H0AlgHoDVADYl37YJgH1cJRHl6mu9QSciCwEsBfAXALNVtScpHQYwO2VMk4i0ikir9zcYEZXOhMMuIlMB/AHAj1X15Niajq6mGXdFjao2q2qjqjZmXTxARIWbUNhFZDJGg/5bVd2cXNwrIvVJvR5A+tvsRJQ7t/Umoz2CVwB0qurPx5S2AlgPYEPy8Q3vuoaHh9Hd3Z1a95bbdnV1pdZqamrMsd4plb02ztGjR1NrR44cMcdOmmTfzd7yWq/NYy0z9U5p7C3ltH5uAFiyZIlZHxwcTK157dDjx4+bde9+s+ZuteUAvzXnjfe2bLaWFp84ccIc29DQkFrr6OhIrU2kz34HgH8G0C4iu5PLnsVoyH8vIo8DOAjA3sibiHLlhl1V/wdA2hEA3y3udIioVHi4LFEQDDtREAw7URAMO1EQDDtREGVd4jo0NITdu3en1jdv3pxaA4DHHnssteadbtnb3tdbCmotM/X64F7P1Tuy0NsS2lre621V7R3b4G1l3dPTY9at6/fm5h2fkOUxy7p8NsvyWsDu4y9atMgc29vbW9Dt8pmdKAiGnSgIhp0oCIadKAiGnSgIhp0oCIadKIiybtksIplu7L777kutPf300+bYWbNmmXVv3bbVV/X6xV6f3Ouze/1m6/qtUxYDfp/dO4bAq1s/mzfWm7vHGm/1qifCe8y8U0lb69nb2trMsWvX2qvJVZVbNhNFxrATBcGwEwXBsBMFwbATBcGwEwXBsBMFUfY+u3Wecq83mcXdd99t1l944QWzbvXpa2trzbHeudm9PrzXZ/f6/BZrC23A78Nb+wAA9mM6MDBgjvXuF481d2+9ubeO33tMt23bZtY7OztTay0tLeZYD/vsRMEx7ERBMOxEQTDsREEw7ERBMOxEQTDsREG4fXYRWQDgNwBmA1AAzar6HyLyHIB/AXBhc/JnVfVt57rK19QvoxtvvNGsZ90bfv78+Wb9wIEDqTWvn7xv3z6zTt88aX32iWwSMQLgJ6q6S0SmAfhIRC4cMfALVf33Yk2SiEpnIvuz9wDoST7vF5FOAPNKPTEiKq6v9Te7iCwEsBTAX5KLnhKRNhF5VURmpIxpEpFWEWnNNFMiymTCYReRqQD+AODHqnoSwC8BfAtAA0af+X823jhVbVbVRlVtLMJ8iahAEwq7iEzGaNB/q6qbAUBVe1X1nKqeB/ArAMtKN00iysoNu4yeovMVAJ2q+vMxl9eP+bbvAego/vSIqFgm0npbDuC/AbQDuLBe8VkA6zD6El4BHADwg+TNPOu6LsnWG1ElSWu9faPOG09EPq5nJwqOYScKgmEnCoJhJwqCYScKgmEnCoJhJwqCYScKgmEnCoJhJwqCYScKgmEnCoJhJwqCYScKYiJnly2mowAOjvm6LrmsElXq3Cp1XgDnVqhizu3atEJZ17N/5cZFWiv13HSVOrdKnRfAuRWqXHPjy3iiIBh2oiDyDntzzrdvqdS5Veq8AM6tUGWZW65/sxNR+eT9zE5EZcKwEwWRS9hFZJWI/FVE9orIM3nMIY2IHBCRdhHZnff+dMkeen0i0jHmspkisk1EPkk+jrvHXk5ze05EupP7breI3J/T3BaIyJ9FZI+IfCwiP0ouz/W+M+ZVlvut7H+zi0gVgL8BWAGgC8BOAOtUdU9ZJ5JCRA4AaFTV3A/AEJG7AAwA+I2q/kNy2YsAjqnqhuQ/yhmq+q8VMrfnAAzkvY13sltR/dhtxgGsAfAocrzvjHmtRRnutzye2ZcB2Kuq+1V1GMDvAKzOYR4VT1XfB3DsootXA9iUfL4Jo78sZZcyt4qgqj2quiv5vB/AhW3Gc73vjHmVRR5hnwfg0Jivu1BZ+70rgD+KyEci0pT3ZMYxe8w2W4cBzM5zMuNwt/Eup4u2Ga+Y+66Q7c+z4ht0X7VcVf8JwH0Afpi8XK1IOvo3WCX1Tie0jXe5jLPN+JfyvO8K3f48qzzC3g1gwZiv5yeXVQRV7U4+9gHYgsrbirr3wg66yce+nOfzpUraxnu8bcZRAfddntuf5xH2nQAWi8giEZkC4PsAtuYwj68QkZrkjROISA2Alai8rai3AliffL4ewBs5zuXvVMo23mnbjCPn+y737c9Vtez/ANyP0Xfk9wH4tzzmkDKv6wD8b/Lv47znBuB1jL6sO4vR9zYeB3A1gO0APgHwJwAzK2hu/4nRrb3bMBqs+pzmthyjL9HbAOxO/t2f931nzKss9xsPlyUKgm/QEQXBsBMFwbATBcGwEwXBsBMFwbATBcGwEwXx//5fN5ZQVuVBAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# Build a Multi Layer Perceptron model by using Pytorch\n","# Problem dataset: MNIST\n","# Build a model has 4 layers include 1 'input' layer, 2 'hidden' layers, 1 'output' layer.\n","# 'input' layer has 782 nodes (input_size), 'hidden 1' layer has 100 nodes, 'hidden 2' layer has 100 nodes and 'output' layer has 25 nodes.\n","# The activation of each node in 'input' layer and 'hidden' layer is 'ReLU'\n","# The actiation of each node in 'output' layer is 'Softmax'\n","# 'out_features' value of 'output' layer is 10 (n_classes)"],"metadata":{"id":"VRVVOZTdj2lK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Build MLP model"],"metadata":{"id":"3P91r2qtU15L"}},{"cell_type":"code","source":["#Build a MLP model by using Pytorch\n","#Approach 1\n","class MLP(nn.Module):\n","  def __init__(self, input_size, n_classes):\n","    super().__init__()\n","    self.input_layer = nn.Linear(input_size, 100)\n","    self.hidden_layer_1 = nn.Linear(100,100)\n","    self.hidden_layer_2 = nn.Linear(100,50)\n","    self.hidden_layer_3 = nn.Linear(50,25)\n","    self.output_layer = nn.Linear(25,n_classes)\n","\n","  def forward(self, X):\n","    X = self.input_layer(X)\n","    X = F.relu(X)\n","    X = self.hidden_layer_1(X)\n","    X = F.relu(X)\n","    X = self.hidden_layer_2(X)\n","    X = F.relu(X)\n","    X = self.hidden_layer_3(X)\n","    X = F.relu(X)\n","    X = self.output_layer(X)\n","    prob = F.softmax(X, dim=1)\n","    return prob "],"metadata":{"id":"6Jm9JdkTlBN0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Build a MLP model by using Pytorch\n","#Approach 2\n","class MLP(nn.Module):\n","  def __init__(self, input_size, n_classes):\n","    super().___init__()\n","    self.model = nn.Sequential(\n","        nn.Linear(input_size, 100),\n","        nn.ReLU(),\n","        nn.Linear(100,100),\n","        nn.ReLU(),\n","        nn.Linear(100,50),\n","        nn.ReLU(),\n","        nn.Linear(50,25),\n","        nn.ReLU(),\n","        nn.Linear(25,n_classes),\n","        nn.Softmax(dim=1)\n","    )\n","  def forward(self, X):\n","    prob = self.model(X)\n","    return prob"],"metadata":{"id":"0BU-zO6bmuuK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Build a MLP model by using Pytorch\n","model = MLP(input_size=input_size, n_classes=n_classes).to(device)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qrbzBgq9nazW","executionInfo":{"status":"ok","timestamp":1639276142800,"user_tz":-420,"elapsed":452,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"outputId":"f0d0e64e-0ca5-4f05-dcf4-436d9df1034f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MLP(\n","  (input_layer): Linear(in_features=784, out_features=100, bias=True)\n","  (hidden_layer_1): Linear(in_features=100, out_features=100, bias=True)\n","  (hidden_layer_2): Linear(in_features=100, out_features=50, bias=True)\n","  (hidden_layer_3): Linear(in_features=50, out_features=25, bias=True)\n","  (output_layer): Linear(in_features=25, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["#Define the loss and the optimization algorithm\n","criterion = nn.CrossEntropyLoss() # Loss function: Cross entropy\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate) # Optimizer: Adam"],"metadata":{"id":"ng9vR46en-S0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training model"],"metadata":{"id":"w9n-rMSYU-qx"}},{"cell_type":"code","source":["#Training model\n","for epoch in range(n_epochs):\n","  for batch_idx, (data, targets) in enumerate(train_loader):\n","    # Get data to GPU\n","    data = data.to(device) # Put our images to the GPU if GPU is available\n","    targets = targets.to(device) # Put our labels to the GPU as well\n","\n","    # Chage to the correct tensor shape\n","    # Our data is in the form (batch_size, color_channel, w,h) (64,1,28,28)\n","    # We need to change it to (batch_size, color_channel* w *h)(64, 784)\n","    data = data.reshape(data.shape[0],-1)\n","\n","    # forward pass\n","    scores = model(data)\n","    loss = criterion(scores, targets) # Compute the loss/cost function 3 for this batch\n","\n","    # backward pass\n","    optimizer.zero_grad() # empty the optimizer first\n","    loss.backward() # compute gradient dJ/dw's\n","\n","    # Gradient descent\n","    optimizer.step()\n","    \n","    if (batch_idx+1)%100 == 0:\n","      print(f'Epoch {epoch+1}/{n_epochs}, Batch {batch_idx+1}, Loss: {loss.item():.2f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n3FHBFifoYq_","executionInfo":{"status":"ok","timestamp":1639276785188,"user_tz":-420,"elapsed":571760,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"outputId":"55c8935d-987d-4063-ea8c-d1d01df6ba15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50, Batch 100, Loss: 1.92\n","Epoch 1/50, Batch 200, Loss: 1.72\n","Epoch 1/50, Batch 300, Loss: 1.78\n","Epoch 1/50, Batch 400, Loss: 1.76\n","Epoch 1/50, Batch 500, Loss: 1.81\n","Epoch 1/50, Batch 600, Loss: 1.76\n","Epoch 1/50, Batch 700, Loss: 1.72\n","Epoch 1/50, Batch 800, Loss: 1.84\n","Epoch 1/50, Batch 900, Loss: 1.78\n","Epoch 2/50, Batch 100, Loss: 1.69\n","Epoch 2/50, Batch 200, Loss: 1.71\n","Epoch 2/50, Batch 300, Loss: 1.76\n","Epoch 2/50, Batch 400, Loss: 1.72\n","Epoch 2/50, Batch 500, Loss: 1.73\n","Epoch 2/50, Batch 600, Loss: 1.73\n","Epoch 2/50, Batch 700, Loss: 1.65\n","Epoch 2/50, Batch 800, Loss: 1.66\n","Epoch 2/50, Batch 900, Loss: 1.67\n","Epoch 3/50, Batch 100, Loss: 1.76\n","Epoch 3/50, Batch 200, Loss: 1.64\n","Epoch 3/50, Batch 300, Loss: 1.68\n","Epoch 3/50, Batch 400, Loss: 1.67\n","Epoch 3/50, Batch 500, Loss: 1.63\n","Epoch 3/50, Batch 600, Loss: 1.67\n","Epoch 3/50, Batch 700, Loss: 1.77\n","Epoch 3/50, Batch 800, Loss: 1.70\n","Epoch 3/50, Batch 900, Loss: 1.69\n","Epoch 4/50, Batch 100, Loss: 1.60\n","Epoch 4/50, Batch 200, Loss: 1.66\n","Epoch 4/50, Batch 300, Loss: 1.81\n","Epoch 4/50, Batch 400, Loss: 1.68\n","Epoch 4/50, Batch 500, Loss: 1.60\n","Epoch 4/50, Batch 600, Loss: 1.70\n","Epoch 4/50, Batch 700, Loss: 1.65\n","Epoch 4/50, Batch 800, Loss: 1.63\n","Epoch 4/50, Batch 900, Loss: 1.69\n","Epoch 5/50, Batch 100, Loss: 1.66\n","Epoch 5/50, Batch 200, Loss: 1.69\n","Epoch 5/50, Batch 300, Loss: 1.62\n","Epoch 5/50, Batch 400, Loss: 1.66\n","Epoch 5/50, Batch 500, Loss: 1.73\n","Epoch 5/50, Batch 600, Loss: 1.67\n","Epoch 5/50, Batch 700, Loss: 1.62\n","Epoch 5/50, Batch 800, Loss: 1.63\n","Epoch 5/50, Batch 900, Loss: 1.72\n","Epoch 6/50, Batch 100, Loss: 1.63\n","Epoch 6/50, Batch 200, Loss: 1.62\n","Epoch 6/50, Batch 300, Loss: 1.66\n","Epoch 6/50, Batch 400, Loss: 1.59\n","Epoch 6/50, Batch 500, Loss: 1.60\n","Epoch 6/50, Batch 600, Loss: 1.52\n","Epoch 6/50, Batch 700, Loss: 1.56\n","Epoch 6/50, Batch 800, Loss: 1.68\n","Epoch 6/50, Batch 900, Loss: 1.62\n","Epoch 7/50, Batch 100, Loss: 1.56\n","Epoch 7/50, Batch 200, Loss: 1.65\n","Epoch 7/50, Batch 300, Loss: 1.55\n","Epoch 7/50, Batch 400, Loss: 1.61\n","Epoch 7/50, Batch 500, Loss: 1.62\n","Epoch 7/50, Batch 600, Loss: 1.54\n","Epoch 7/50, Batch 700, Loss: 1.68\n","Epoch 7/50, Batch 800, Loss: 1.63\n","Epoch 7/50, Batch 900, Loss: 1.60\n","Epoch 8/50, Batch 100, Loss: 1.65\n","Epoch 8/50, Batch 200, Loss: 1.60\n","Epoch 8/50, Batch 300, Loss: 1.62\n","Epoch 8/50, Batch 400, Loss: 1.64\n","Epoch 8/50, Batch 500, Loss: 1.56\n","Epoch 8/50, Batch 600, Loss: 1.62\n","Epoch 8/50, Batch 700, Loss: 1.63\n","Epoch 8/50, Batch 800, Loss: 1.65\n","Epoch 8/50, Batch 900, Loss: 1.57\n","Epoch 9/50, Batch 100, Loss: 1.58\n","Epoch 9/50, Batch 200, Loss: 1.57\n","Epoch 9/50, Batch 300, Loss: 1.61\n","Epoch 9/50, Batch 400, Loss: 1.63\n","Epoch 9/50, Batch 500, Loss: 1.59\n","Epoch 9/50, Batch 600, Loss: 1.63\n","Epoch 9/50, Batch 700, Loss: 1.55\n","Epoch 9/50, Batch 800, Loss: 1.62\n","Epoch 9/50, Batch 900, Loss: 1.58\n","Epoch 10/50, Batch 100, Loss: 1.57\n","Epoch 10/50, Batch 200, Loss: 1.55\n","Epoch 10/50, Batch 300, Loss: 1.62\n","Epoch 10/50, Batch 400, Loss: 1.63\n","Epoch 10/50, Batch 500, Loss: 1.62\n","Epoch 10/50, Batch 600, Loss: 1.61\n","Epoch 10/50, Batch 700, Loss: 1.62\n","Epoch 10/50, Batch 800, Loss: 1.62\n","Epoch 10/50, Batch 900, Loss: 1.54\n","Epoch 11/50, Batch 100, Loss: 1.60\n","Epoch 11/50, Batch 200, Loss: 1.61\n","Epoch 11/50, Batch 300, Loss: 1.66\n","Epoch 11/50, Batch 400, Loss: 1.61\n","Epoch 11/50, Batch 500, Loss: 1.55\n","Epoch 11/50, Batch 600, Loss: 1.63\n","Epoch 11/50, Batch 700, Loss: 1.55\n","Epoch 11/50, Batch 800, Loss: 1.61\n","Epoch 11/50, Batch 900, Loss: 1.60\n","Epoch 12/50, Batch 100, Loss: 1.62\n","Epoch 12/50, Batch 200, Loss: 1.56\n","Epoch 12/50, Batch 300, Loss: 1.55\n","Epoch 12/50, Batch 400, Loss: 1.62\n","Epoch 12/50, Batch 500, Loss: 1.60\n","Epoch 12/50, Batch 600, Loss: 1.58\n","Epoch 12/50, Batch 700, Loss: 1.61\n","Epoch 12/50, Batch 800, Loss: 1.65\n","Epoch 12/50, Batch 900, Loss: 1.66\n","Epoch 13/50, Batch 100, Loss: 1.60\n","Epoch 13/50, Batch 200, Loss: 1.54\n","Epoch 13/50, Batch 300, Loss: 1.58\n","Epoch 13/50, Batch 400, Loss: 1.55\n","Epoch 13/50, Batch 500, Loss: 1.53\n","Epoch 13/50, Batch 600, Loss: 1.51\n","Epoch 13/50, Batch 700, Loss: 1.59\n","Epoch 13/50, Batch 800, Loss: 1.58\n","Epoch 13/50, Batch 900, Loss: 1.65\n","Epoch 14/50, Batch 100, Loss: 1.54\n","Epoch 14/50, Batch 200, Loss: 1.58\n","Epoch 14/50, Batch 300, Loss: 1.62\n","Epoch 14/50, Batch 400, Loss: 1.59\n","Epoch 14/50, Batch 500, Loss: 1.60\n","Epoch 14/50, Batch 600, Loss: 1.54\n","Epoch 14/50, Batch 700, Loss: 1.54\n","Epoch 14/50, Batch 800, Loss: 1.57\n","Epoch 14/50, Batch 900, Loss: 1.61\n","Epoch 15/50, Batch 100, Loss: 1.60\n","Epoch 15/50, Batch 200, Loss: 1.54\n","Epoch 15/50, Batch 300, Loss: 1.56\n","Epoch 15/50, Batch 400, Loss: 1.59\n","Epoch 15/50, Batch 500, Loss: 1.60\n","Epoch 15/50, Batch 600, Loss: 1.56\n","Epoch 15/50, Batch 700, Loss: 1.60\n","Epoch 15/50, Batch 800, Loss: 1.57\n","Epoch 15/50, Batch 900, Loss: 1.57\n","Epoch 16/50, Batch 100, Loss: 1.62\n","Epoch 16/50, Batch 200, Loss: 1.59\n","Epoch 16/50, Batch 300, Loss: 1.59\n","Epoch 16/50, Batch 400, Loss: 1.60\n","Epoch 16/50, Batch 500, Loss: 1.57\n","Epoch 16/50, Batch 600, Loss: 1.68\n","Epoch 16/50, Batch 700, Loss: 1.62\n","Epoch 16/50, Batch 800, Loss: 1.51\n","Epoch 16/50, Batch 900, Loss: 1.55\n","Epoch 17/50, Batch 100, Loss: 1.57\n","Epoch 17/50, Batch 200, Loss: 1.53\n","Epoch 17/50, Batch 300, Loss: 1.59\n","Epoch 17/50, Batch 400, Loss: 1.63\n","Epoch 17/50, Batch 500, Loss: 1.57\n","Epoch 17/50, Batch 600, Loss: 1.63\n","Epoch 17/50, Batch 700, Loss: 1.55\n","Epoch 17/50, Batch 800, Loss: 1.60\n","Epoch 17/50, Batch 900, Loss: 1.60\n","Epoch 18/50, Batch 100, Loss: 1.66\n","Epoch 18/50, Batch 200, Loss: 1.52\n","Epoch 18/50, Batch 300, Loss: 1.57\n","Epoch 18/50, Batch 400, Loss: 1.59\n","Epoch 18/50, Batch 500, Loss: 1.76\n","Epoch 18/50, Batch 600, Loss: 1.59\n","Epoch 18/50, Batch 700, Loss: 1.57\n","Epoch 18/50, Batch 800, Loss: 1.51\n","Epoch 18/50, Batch 900, Loss: 1.56\n","Epoch 19/50, Batch 100, Loss: 1.68\n","Epoch 19/50, Batch 200, Loss: 1.59\n","Epoch 19/50, Batch 300, Loss: 1.55\n","Epoch 19/50, Batch 400, Loss: 1.59\n","Epoch 19/50, Batch 500, Loss: 1.49\n","Epoch 19/50, Batch 600, Loss: 1.57\n","Epoch 19/50, Batch 700, Loss: 1.53\n","Epoch 19/50, Batch 800, Loss: 1.64\n","Epoch 19/50, Batch 900, Loss: 1.64\n","Epoch 20/50, Batch 100, Loss: 1.62\n","Epoch 20/50, Batch 200, Loss: 1.55\n","Epoch 20/50, Batch 300, Loss: 1.62\n","Epoch 20/50, Batch 400, Loss: 1.59\n","Epoch 20/50, Batch 500, Loss: 1.54\n","Epoch 20/50, Batch 600, Loss: 1.60\n","Epoch 20/50, Batch 700, Loss: 1.56\n","Epoch 20/50, Batch 800, Loss: 1.62\n","Epoch 20/50, Batch 900, Loss: 1.63\n","Epoch 21/50, Batch 100, Loss: 1.62\n","Epoch 21/50, Batch 200, Loss: 1.57\n","Epoch 21/50, Batch 300, Loss: 1.55\n","Epoch 21/50, Batch 400, Loss: 1.55\n","Epoch 21/50, Batch 500, Loss: 1.61\n","Epoch 21/50, Batch 600, Loss: 1.61\n","Epoch 21/50, Batch 700, Loss: 1.58\n","Epoch 21/50, Batch 800, Loss: 1.57\n","Epoch 21/50, Batch 900, Loss: 1.59\n","Epoch 22/50, Batch 100, Loss: 1.60\n","Epoch 22/50, Batch 200, Loss: 1.65\n","Epoch 22/50, Batch 300, Loss: 1.66\n","Epoch 22/50, Batch 400, Loss: 1.52\n","Epoch 22/50, Batch 500, Loss: 1.61\n","Epoch 22/50, Batch 600, Loss: 1.54\n","Epoch 22/50, Batch 700, Loss: 1.60\n","Epoch 22/50, Batch 800, Loss: 1.57\n","Epoch 22/50, Batch 900, Loss: 1.54\n","Epoch 23/50, Batch 100, Loss: 1.61\n","Epoch 23/50, Batch 200, Loss: 1.54\n","Epoch 23/50, Batch 300, Loss: 1.57\n","Epoch 23/50, Batch 400, Loss: 1.55\n","Epoch 23/50, Batch 500, Loss: 1.52\n","Epoch 23/50, Batch 600, Loss: 1.65\n","Epoch 23/50, Batch 700, Loss: 1.57\n","Epoch 23/50, Batch 800, Loss: 1.60\n","Epoch 23/50, Batch 900, Loss: 1.62\n","Epoch 24/50, Batch 100, Loss: 1.49\n","Epoch 24/50, Batch 200, Loss: 1.65\n","Epoch 24/50, Batch 300, Loss: 1.57\n","Epoch 24/50, Batch 400, Loss: 1.63\n","Epoch 24/50, Batch 500, Loss: 1.59\n","Epoch 24/50, Batch 600, Loss: 1.66\n","Epoch 24/50, Batch 700, Loss: 1.54\n","Epoch 24/50, Batch 800, Loss: 1.54\n","Epoch 24/50, Batch 900, Loss: 1.54\n","Epoch 25/50, Batch 100, Loss: 1.54\n","Epoch 25/50, Batch 200, Loss: 1.64\n","Epoch 25/50, Batch 300, Loss: 1.56\n","Epoch 25/50, Batch 400, Loss: 1.51\n","Epoch 25/50, Batch 500, Loss: 1.59\n","Epoch 25/50, Batch 600, Loss: 1.64\n","Epoch 25/50, Batch 700, Loss: 1.60\n","Epoch 25/50, Batch 800, Loss: 1.61\n","Epoch 25/50, Batch 900, Loss: 1.55\n","Epoch 26/50, Batch 100, Loss: 1.65\n","Epoch 26/50, Batch 200, Loss: 1.55\n","Epoch 26/50, Batch 300, Loss: 1.65\n","Epoch 26/50, Batch 400, Loss: 1.59\n","Epoch 26/50, Batch 500, Loss: 1.57\n","Epoch 26/50, Batch 600, Loss: 1.55\n","Epoch 26/50, Batch 700, Loss: 1.57\n","Epoch 26/50, Batch 800, Loss: 1.62\n","Epoch 26/50, Batch 900, Loss: 1.57\n","Epoch 27/50, Batch 100, Loss: 1.51\n","Epoch 27/50, Batch 200, Loss: 1.59\n","Epoch 27/50, Batch 300, Loss: 1.58\n","Epoch 27/50, Batch 400, Loss: 1.59\n","Epoch 27/50, Batch 500, Loss: 1.57\n","Epoch 27/50, Batch 600, Loss: 1.57\n","Epoch 27/50, Batch 700, Loss: 1.57\n","Epoch 27/50, Batch 800, Loss: 1.54\n","Epoch 27/50, Batch 900, Loss: 1.55\n","Epoch 28/50, Batch 100, Loss: 1.61\n","Epoch 28/50, Batch 200, Loss: 1.57\n","Epoch 28/50, Batch 300, Loss: 1.56\n","Epoch 28/50, Batch 400, Loss: 1.55\n","Epoch 28/50, Batch 500, Loss: 1.59\n","Epoch 28/50, Batch 600, Loss: 1.55\n","Epoch 28/50, Batch 700, Loss: 1.57\n","Epoch 28/50, Batch 800, Loss: 1.61\n","Epoch 28/50, Batch 900, Loss: 1.54\n","Epoch 29/50, Batch 100, Loss: 1.54\n","Epoch 29/50, Batch 200, Loss: 1.58\n","Epoch 29/50, Batch 300, Loss: 1.52\n","Epoch 29/50, Batch 400, Loss: 1.65\n","Epoch 29/50, Batch 500, Loss: 1.60\n","Epoch 29/50, Batch 600, Loss: 1.63\n","Epoch 29/50, Batch 700, Loss: 1.64\n","Epoch 29/50, Batch 800, Loss: 1.62\n","Epoch 29/50, Batch 900, Loss: 1.54\n","Epoch 30/50, Batch 100, Loss: 1.55\n","Epoch 30/50, Batch 200, Loss: 1.54\n","Epoch 30/50, Batch 300, Loss: 1.62\n","Epoch 30/50, Batch 400, Loss: 1.59\n","Epoch 30/50, Batch 500, Loss: 1.62\n","Epoch 30/50, Batch 600, Loss: 1.62\n","Epoch 30/50, Batch 700, Loss: 1.54\n","Epoch 30/50, Batch 800, Loss: 1.58\n","Epoch 30/50, Batch 900, Loss: 1.57\n","Epoch 31/50, Batch 100, Loss: 1.63\n","Epoch 31/50, Batch 200, Loss: 1.55\n","Epoch 31/50, Batch 300, Loss: 1.56\n","Epoch 31/50, Batch 400, Loss: 1.57\n","Epoch 31/50, Batch 500, Loss: 1.70\n","Epoch 31/50, Batch 600, Loss: 1.64\n","Epoch 31/50, Batch 700, Loss: 1.56\n","Epoch 31/50, Batch 800, Loss: 1.57\n","Epoch 31/50, Batch 900, Loss: 1.63\n","Epoch 32/50, Batch 100, Loss: 1.55\n","Epoch 32/50, Batch 200, Loss: 1.62\n","Epoch 32/50, Batch 300, Loss: 1.58\n","Epoch 32/50, Batch 400, Loss: 1.55\n","Epoch 32/50, Batch 500, Loss: 1.56\n","Epoch 32/50, Batch 600, Loss: 1.68\n","Epoch 32/50, Batch 700, Loss: 1.62\n","Epoch 32/50, Batch 800, Loss: 1.59\n","Epoch 32/50, Batch 900, Loss: 1.52\n","Epoch 33/50, Batch 100, Loss: 1.58\n","Epoch 33/50, Batch 200, Loss: 1.59\n","Epoch 33/50, Batch 300, Loss: 1.57\n","Epoch 33/50, Batch 400, Loss: 1.52\n","Epoch 33/50, Batch 500, Loss: 1.60\n","Epoch 33/50, Batch 600, Loss: 1.55\n","Epoch 33/50, Batch 700, Loss: 1.57\n","Epoch 33/50, Batch 800, Loss: 1.51\n","Epoch 33/50, Batch 900, Loss: 1.57\n","Epoch 34/50, Batch 100, Loss: 1.59\n","Epoch 34/50, Batch 200, Loss: 1.55\n","Epoch 34/50, Batch 300, Loss: 1.67\n","Epoch 34/50, Batch 400, Loss: 1.62\n","Epoch 34/50, Batch 500, Loss: 1.53\n","Epoch 34/50, Batch 600, Loss: 1.50\n","Epoch 34/50, Batch 700, Loss: 1.70\n","Epoch 34/50, Batch 800, Loss: 1.52\n","Epoch 34/50, Batch 900, Loss: 1.59\n","Epoch 35/50, Batch 100, Loss: 1.59\n","Epoch 35/50, Batch 200, Loss: 1.60\n","Epoch 35/50, Batch 300, Loss: 1.52\n","Epoch 35/50, Batch 400, Loss: 1.58\n","Epoch 35/50, Batch 500, Loss: 1.59\n","Epoch 35/50, Batch 600, Loss: 1.65\n","Epoch 35/50, Batch 700, Loss: 1.57\n","Epoch 35/50, Batch 800, Loss: 1.63\n","Epoch 35/50, Batch 900, Loss: 1.60\n","Epoch 36/50, Batch 100, Loss: 1.62\n","Epoch 36/50, Batch 200, Loss: 1.57\n","Epoch 36/50, Batch 300, Loss: 1.56\n","Epoch 36/50, Batch 400, Loss: 1.58\n","Epoch 36/50, Batch 500, Loss: 1.55\n","Epoch 36/50, Batch 600, Loss: 1.60\n","Epoch 36/50, Batch 700, Loss: 1.62\n","Epoch 36/50, Batch 800, Loss: 1.60\n","Epoch 36/50, Batch 900, Loss: 1.57\n","Epoch 37/50, Batch 100, Loss: 1.60\n","Epoch 37/50, Batch 200, Loss: 1.61\n","Epoch 37/50, Batch 300, Loss: 1.63\n","Epoch 37/50, Batch 400, Loss: 1.56\n","Epoch 37/50, Batch 500, Loss: 1.69\n","Epoch 37/50, Batch 600, Loss: 1.59\n","Epoch 37/50, Batch 700, Loss: 1.65\n","Epoch 37/50, Batch 800, Loss: 1.59\n","Epoch 37/50, Batch 900, Loss: 1.63\n","Epoch 38/50, Batch 100, Loss: 1.54\n","Epoch 38/50, Batch 200, Loss: 1.59\n","Epoch 38/50, Batch 300, Loss: 1.57\n","Epoch 38/50, Batch 400, Loss: 1.59\n","Epoch 38/50, Batch 500, Loss: 1.57\n","Epoch 38/50, Batch 600, Loss: 1.55\n","Epoch 38/50, Batch 700, Loss: 1.57\n","Epoch 38/50, Batch 800, Loss: 1.49\n","Epoch 38/50, Batch 900, Loss: 1.54\n","Epoch 39/50, Batch 100, Loss: 1.54\n","Epoch 39/50, Batch 200, Loss: 1.57\n","Epoch 39/50, Batch 300, Loss: 1.54\n","Epoch 39/50, Batch 400, Loss: 1.53\n","Epoch 39/50, Batch 500, Loss: 1.57\n","Epoch 39/50, Batch 600, Loss: 1.54\n","Epoch 39/50, Batch 700, Loss: 1.60\n","Epoch 39/50, Batch 800, Loss: 1.71\n","Epoch 39/50, Batch 900, Loss: 1.51\n","Epoch 40/50, Batch 100, Loss: 1.59\n","Epoch 40/50, Batch 200, Loss: 1.56\n","Epoch 40/50, Batch 300, Loss: 1.63\n","Epoch 40/50, Batch 400, Loss: 1.59\n","Epoch 40/50, Batch 500, Loss: 1.63\n","Epoch 40/50, Batch 600, Loss: 1.63\n","Epoch 40/50, Batch 700, Loss: 1.55\n","Epoch 40/50, Batch 800, Loss: 1.60\n","Epoch 40/50, Batch 900, Loss: 1.63\n","Epoch 41/50, Batch 100, Loss: 1.63\n","Epoch 41/50, Batch 200, Loss: 1.54\n","Epoch 41/50, Batch 300, Loss: 1.54\n","Epoch 41/50, Batch 400, Loss: 1.62\n","Epoch 41/50, Batch 500, Loss: 1.64\n","Epoch 41/50, Batch 600, Loss: 1.62\n","Epoch 41/50, Batch 700, Loss: 1.57\n","Epoch 41/50, Batch 800, Loss: 1.58\n","Epoch 41/50, Batch 900, Loss: 1.52\n","Epoch 42/50, Batch 100, Loss: 1.57\n","Epoch 42/50, Batch 200, Loss: 1.59\n","Epoch 42/50, Batch 300, Loss: 1.55\n","Epoch 42/50, Batch 400, Loss: 1.57\n","Epoch 42/50, Batch 500, Loss: 1.55\n","Epoch 42/50, Batch 600, Loss: 1.62\n","Epoch 42/50, Batch 700, Loss: 1.60\n","Epoch 42/50, Batch 800, Loss: 1.58\n","Epoch 42/50, Batch 900, Loss: 1.63\n","Epoch 43/50, Batch 100, Loss: 1.55\n","Epoch 43/50, Batch 200, Loss: 1.56\n","Epoch 43/50, Batch 300, Loss: 1.59\n","Epoch 43/50, Batch 400, Loss: 1.53\n","Epoch 43/50, Batch 500, Loss: 1.59\n","Epoch 43/50, Batch 600, Loss: 1.55\n","Epoch 43/50, Batch 700, Loss: 1.59\n","Epoch 43/50, Batch 800, Loss: 1.57\n","Epoch 43/50, Batch 900, Loss: 1.61\n","Epoch 44/50, Batch 100, Loss: 1.63\n","Epoch 44/50, Batch 200, Loss: 1.61\n","Epoch 44/50, Batch 300, Loss: 1.60\n","Epoch 44/50, Batch 400, Loss: 1.58\n","Epoch 44/50, Batch 500, Loss: 1.55\n","Epoch 44/50, Batch 600, Loss: 1.60\n","Epoch 44/50, Batch 700, Loss: 1.65\n","Epoch 44/50, Batch 800, Loss: 1.52\n","Epoch 44/50, Batch 900, Loss: 1.62\n","Epoch 45/50, Batch 100, Loss: 1.59\n","Epoch 45/50, Batch 200, Loss: 1.52\n","Epoch 45/50, Batch 300, Loss: 1.63\n","Epoch 45/50, Batch 400, Loss: 1.62\n","Epoch 45/50, Batch 500, Loss: 1.59\n","Epoch 45/50, Batch 600, Loss: 1.55\n","Epoch 45/50, Batch 700, Loss: 1.57\n","Epoch 45/50, Batch 800, Loss: 1.62\n","Epoch 45/50, Batch 900, Loss: 1.53\n","Epoch 46/50, Batch 100, Loss: 1.55\n","Epoch 46/50, Batch 200, Loss: 1.63\n","Epoch 46/50, Batch 300, Loss: 1.58\n","Epoch 46/50, Batch 400, Loss: 1.51\n","Epoch 46/50, Batch 500, Loss: 1.65\n","Epoch 46/50, Batch 600, Loss: 1.64\n","Epoch 46/50, Batch 700, Loss: 1.59\n","Epoch 46/50, Batch 800, Loss: 1.57\n","Epoch 46/50, Batch 900, Loss: 1.64\n","Epoch 47/50, Batch 100, Loss: 1.63\n","Epoch 47/50, Batch 200, Loss: 1.60\n","Epoch 47/50, Batch 300, Loss: 1.57\n","Epoch 47/50, Batch 400, Loss: 1.54\n","Epoch 47/50, Batch 500, Loss: 1.57\n","Epoch 47/50, Batch 600, Loss: 1.57\n","Epoch 47/50, Batch 700, Loss: 1.59\n","Epoch 47/50, Batch 800, Loss: 1.60\n","Epoch 47/50, Batch 900, Loss: 1.57\n","Epoch 48/50, Batch 100, Loss: 1.62\n","Epoch 48/50, Batch 200, Loss: 1.51\n","Epoch 48/50, Batch 300, Loss: 1.54\n","Epoch 48/50, Batch 400, Loss: 1.61\n","Epoch 48/50, Batch 500, Loss: 1.51\n","Epoch 48/50, Batch 600, Loss: 1.60\n","Epoch 48/50, Batch 700, Loss: 1.52\n","Epoch 48/50, Batch 800, Loss: 1.54\n","Epoch 48/50, Batch 900, Loss: 1.55\n","Epoch 49/50, Batch 100, Loss: 1.59\n","Epoch 49/50, Batch 200, Loss: 1.63\n","Epoch 49/50, Batch 300, Loss: 1.56\n","Epoch 49/50, Batch 400, Loss: 1.58\n","Epoch 49/50, Batch 500, Loss: 1.64\n","Epoch 49/50, Batch 600, Loss: 1.63\n","Epoch 49/50, Batch 700, Loss: 1.62\n","Epoch 49/50, Batch 800, Loss: 1.57\n","Epoch 49/50, Batch 900, Loss: 1.63\n","Epoch 50/50, Batch 100, Loss: 1.56\n","Epoch 50/50, Batch 200, Loss: 1.63\n","Epoch 50/50, Batch 300, Loss: 1.60\n","Epoch 50/50, Batch 400, Loss: 1.58\n","Epoch 50/50, Batch 500, Loss: 1.65\n","Epoch 50/50, Batch 600, Loss: 1.56\n","Epoch 50/50, Batch 700, Loss: 1.59\n","Epoch 50/50, Batch 800, Loss: 1.55\n","Epoch 50/50, Batch 900, Loss: 1.57\n"]}]},{"cell_type":"markdown","source":["## Performance Evaluation"],"metadata":{"id":"Go4Vvx08VCRY"}},{"cell_type":"code","source":["# Performance Evaluation\n","def get_accuracy(loader, model):\n","  if loader.dataset.train:\n","    print('Getting accuracy on training data.')\n","  else:\n","    print('Getting accuracy on testing data.')\n","  n_corrects = 0\n","  n_samples = 0\n","  model.eval() # put our model to evaluation mode\n","  with torch.no_grad():\n","    for x,y in loader:\n","      x = x.to(device)\n","      y = y.to(device)\n","      x = x.reshape(x.shape[0], -1)\n","\n","      #forward\n","      scores = model(x) # scores 64 x 10\n","      _, y_pred = scores.max(1)\n","      n_corrects += (y_pred == y).sum()\n","      n_samples += y_pred.size(0)\n","\n","    print(f'We got {n_corrects}/{n_samples} correct. Accuracy = {float(n_corrects)/float(n_samples)* 100.0:.2f}')\n","  model.train() # put our model to train mode again"],"metadata":{"id":"ykYzp9uwrAOP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Performance Evaluation\n","get_accuracy(train_loader, model)\n","get_accuracy(test_loader, model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E7l7krJmstjo","executionInfo":{"status":"ok","timestamp":1639276828078,"user_tz":-420,"elapsed":10846,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"outputId":"d701a64b-73a0-4cd8-ed9c-d3f1096becaa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Getting accuracy on training data.\n","We got 52954/60000 correct. Accuracy = 88.26\n","Getting accuracy on testing data.\n","We got 8619/10000 correct. Accuracy = 86.19\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"MBA3Y8LdhEfw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# FashionMNIST using LeNet5 model"],"metadata":{"id":"kf8SyPuDhH9O"}},{"cell_type":"markdown","source":["## Import nescessary libraries"],"metadata":{"id":"pcJVy0DMhOa7"}},{"cell_type":"code","source":["import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.utils.data import DataLoader\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms"],"metadata":{"id":"weWZbQ5LhdtH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Check 'CPU' or 'GPU'"],"metadata":{"id":"JjQXtZ1Chp82"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"toMwR9uuhdmu","executionInfo":{"status":"ok","timestamp":1639278102503,"user_tz":-420,"elapsed":322,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"outputId":"6f97628b-db41-45cd-cbfa-0e86849936cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["random.seed(1)\n","np.random.seed(1)\n","torch.manual_seed(1)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"],"metadata":{"id":"XwAc2yw9hdhq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hyperparameters\n","\n","n_classes = 10\n","learning_rate = 0.001\n","batch_size = 64\n","n_epochs = 50"],"metadata":{"id":"7-TQBe1LhEYP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transforms = transforms.Compose([transforms.Resize((32,32)),transforms.ToTensor()])"],"metadata":{"id":"fv3N8B11lp5f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prepare FashionMNIST dataset"],"metadata":{"id":"ZrACo7T2h6JV"}},{"cell_type":"code","source":["# LOAD data from Google Drive\n","# Load 'FashionMNIST' dataset\n","train_dataset = datasets.FashionMNIST(root='/content/drive/MyDrive/10. Toán cho KHMT/datasets' , train =True,\n","                              transform=transforms, download=True)\n","train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,shuffle=True)\n","test_dataset = datasets.FashionMNIST(root='/content/drive/MyDrive/10. Toán cho KHMT/datasets' ,train=False,transform=transforms,\n","                              download=True)\n","test_loader = DataLoader(dataset= test_dataset, batch_size=batch_size, shuffle=False)\n"],"metadata":{"id":"hmsgFT7HhESg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Build LeNet5 model"],"metadata":{"id":"cxbXUe6RiLfD"}},{"cell_type":"code","source":["# Build LeNet5 by using Pytorch\n","class LeNet5(nn.Module):\n","  def __init__(self, n_classes):\n","    super().__init__()\n","    self.model = nn.Sequential(\n","        nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride =1),\n","        nn.Tanh(),\n","        nn.AvgPool2d(kernel_size=2),\n","        nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n","        nn.Tanh(),\n","        nn.AvgPool2d(kernel_size=2),\n","        nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n","        nn.Tanh(),\n","        nn.Flatten(),\n","        nn.Linear(in_features=120, out_features=84),\n","        nn.Tanh(),\n","        nn.Linear(in_features= 84, out_features=n_classes),\n","        nn.Softmax(dim=1)\n","    )\n","  def forward(self, X):\n","    prob = self.model(X)\n","    return prob"],"metadata":{"id":"-Fz2jJUWhCx0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = LeNet5(n_classes=n_classes).to(device)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ftk3Zrr4iYOy","executionInfo":{"status":"ok","timestamp":1639278174062,"user_tz":-420,"elapsed":300,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"outputId":"0cad4c49-6731-49f3-8ea9-d01f7ef853f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LeNet5(\n","  (model): Sequential(\n","    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","    (8): Flatten(start_dim=1, end_dim=-1)\n","    (9): Linear(in_features=120, out_features=84, bias=True)\n","    (10): Tanh()\n","    (11): Linear(in_features=84, out_features=10, bias=True)\n","    (12): Softmax(dim=1)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["# Define the loss and the optimization algorithm\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr= learning_rate)"],"metadata":{"id":"kLgDrU_ziaiK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training model"],"metadata":{"id":"66o57ur-ijIc"}},{"cell_type":"code","source":["#Training model\n","\n","for epoch in range(n_epochs):\n","  for batch_idx, (data, targets) in enumerate(train_loader):\n","\n","    data = data.to(device)\n","    targets = targets.to(device)\n","\n","    scores = model(data)\n","    loss = criterion(scores, targets)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    if(batch_idx+1)% 100 ==0:\n","      print(f'Epoch {epoch+1}/{n_epochs}, Batch {batch_idx+1}, Loss: {loss.item():.2f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-iFLBL4pidDC","executionInfo":{"status":"ok","timestamp":1639278966005,"user_tz":-420,"elapsed":786310,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"outputId":"2ab873e6-3646-4ca3-f79b-e3d9b744a899"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50, Batch 100, Loss: 1.86\n","Epoch 1/50, Batch 200, Loss: 1.74\n","Epoch 1/50, Batch 300, Loss: 1.75\n","Epoch 1/50, Batch 400, Loss: 1.61\n","Epoch 1/50, Batch 500, Loss: 1.78\n","Epoch 1/50, Batch 600, Loss: 1.67\n","Epoch 1/50, Batch 700, Loss: 1.72\n","Epoch 1/50, Batch 800, Loss: 1.64\n","Epoch 1/50, Batch 900, Loss: 1.63\n","Epoch 2/50, Batch 100, Loss: 1.62\n","Epoch 2/50, Batch 200, Loss: 1.64\n","Epoch 2/50, Batch 300, Loss: 1.64\n","Epoch 2/50, Batch 400, Loss: 1.67\n","Epoch 2/50, Batch 500, Loss: 1.62\n","Epoch 2/50, Batch 600, Loss: 1.60\n","Epoch 2/50, Batch 700, Loss: 1.61\n","Epoch 2/50, Batch 800, Loss: 1.65\n","Epoch 2/50, Batch 900, Loss: 1.60\n","Epoch 3/50, Batch 100, Loss: 1.61\n","Epoch 3/50, Batch 200, Loss: 1.60\n","Epoch 3/50, Batch 300, Loss: 1.59\n","Epoch 3/50, Batch 400, Loss: 1.60\n","Epoch 3/50, Batch 500, Loss: 1.64\n","Epoch 3/50, Batch 600, Loss: 1.58\n","Epoch 3/50, Batch 700, Loss: 1.64\n","Epoch 3/50, Batch 800, Loss: 1.58\n","Epoch 3/50, Batch 900, Loss: 1.59\n","Epoch 4/50, Batch 100, Loss: 1.69\n","Epoch 4/50, Batch 200, Loss: 1.55\n","Epoch 4/50, Batch 300, Loss: 1.69\n","Epoch 4/50, Batch 400, Loss: 1.60\n","Epoch 4/50, Batch 500, Loss: 1.63\n","Epoch 4/50, Batch 600, Loss: 1.61\n","Epoch 4/50, Batch 700, Loss: 1.57\n","Epoch 4/50, Batch 800, Loss: 1.56\n","Epoch 4/50, Batch 900, Loss: 1.64\n","Epoch 5/50, Batch 100, Loss: 1.56\n","Epoch 5/50, Batch 200, Loss: 1.57\n","Epoch 5/50, Batch 300, Loss: 1.58\n","Epoch 5/50, Batch 400, Loss: 1.55\n","Epoch 5/50, Batch 500, Loss: 1.56\n","Epoch 5/50, Batch 600, Loss: 1.67\n","Epoch 5/50, Batch 700, Loss: 1.66\n","Epoch 5/50, Batch 800, Loss: 1.59\n","Epoch 5/50, Batch 900, Loss: 1.58\n","Epoch 6/50, Batch 100, Loss: 1.62\n","Epoch 6/50, Batch 200, Loss: 1.62\n","Epoch 6/50, Batch 300, Loss: 1.61\n","Epoch 6/50, Batch 400, Loss: 1.58\n","Epoch 6/50, Batch 500, Loss: 1.71\n","Epoch 6/50, Batch 600, Loss: 1.57\n","Epoch 6/50, Batch 700, Loss: 1.63\n","Epoch 6/50, Batch 800, Loss: 1.58\n","Epoch 6/50, Batch 900, Loss: 1.56\n","Epoch 7/50, Batch 100, Loss: 1.67\n","Epoch 7/50, Batch 200, Loss: 1.66\n","Epoch 7/50, Batch 300, Loss: 1.58\n","Epoch 7/50, Batch 400, Loss: 1.64\n","Epoch 7/50, Batch 500, Loss: 1.57\n","Epoch 7/50, Batch 600, Loss: 1.67\n","Epoch 7/50, Batch 700, Loss: 1.50\n","Epoch 7/50, Batch 800, Loss: 1.57\n","Epoch 7/50, Batch 900, Loss: 1.63\n","Epoch 8/50, Batch 100, Loss: 1.54\n","Epoch 8/50, Batch 200, Loss: 1.56\n","Epoch 8/50, Batch 300, Loss: 1.54\n","Epoch 8/50, Batch 400, Loss: 1.57\n","Epoch 8/50, Batch 500, Loss: 1.61\n","Epoch 8/50, Batch 600, Loss: 1.58\n","Epoch 8/50, Batch 700, Loss: 1.64\n","Epoch 8/50, Batch 800, Loss: 1.55\n","Epoch 8/50, Batch 900, Loss: 1.54\n","Epoch 9/50, Batch 100, Loss: 1.59\n","Epoch 9/50, Batch 200, Loss: 1.56\n","Epoch 9/50, Batch 300, Loss: 1.51\n","Epoch 9/50, Batch 400, Loss: 1.57\n","Epoch 9/50, Batch 500, Loss: 1.55\n","Epoch 9/50, Batch 600, Loss: 1.53\n","Epoch 9/50, Batch 700, Loss: 1.62\n","Epoch 9/50, Batch 800, Loss: 1.72\n","Epoch 9/50, Batch 900, Loss: 1.58\n","Epoch 10/50, Batch 100, Loss: 1.56\n","Epoch 10/50, Batch 200, Loss: 1.57\n","Epoch 10/50, Batch 300, Loss: 1.53\n","Epoch 10/50, Batch 400, Loss: 1.51\n","Epoch 10/50, Batch 500, Loss: 1.60\n","Epoch 10/50, Batch 600, Loss: 1.62\n","Epoch 10/50, Batch 700, Loss: 1.58\n","Epoch 10/50, Batch 800, Loss: 1.60\n","Epoch 10/50, Batch 900, Loss: 1.56\n","Epoch 11/50, Batch 100, Loss: 1.53\n","Epoch 11/50, Batch 200, Loss: 1.54\n","Epoch 11/50, Batch 300, Loss: 1.61\n","Epoch 11/50, Batch 400, Loss: 1.56\n","Epoch 11/50, Batch 500, Loss: 1.56\n","Epoch 11/50, Batch 600, Loss: 1.60\n","Epoch 11/50, Batch 700, Loss: 1.61\n","Epoch 11/50, Batch 800, Loss: 1.59\n","Epoch 11/50, Batch 900, Loss: 1.56\n","Epoch 12/50, Batch 100, Loss: 1.61\n","Epoch 12/50, Batch 200, Loss: 1.54\n","Epoch 12/50, Batch 300, Loss: 1.57\n","Epoch 12/50, Batch 400, Loss: 1.52\n","Epoch 12/50, Batch 500, Loss: 1.58\n","Epoch 12/50, Batch 600, Loss: 1.64\n","Epoch 12/50, Batch 700, Loss: 1.51\n","Epoch 12/50, Batch 800, Loss: 1.52\n","Epoch 12/50, Batch 900, Loss: 1.54\n","Epoch 13/50, Batch 100, Loss: 1.61\n","Epoch 13/50, Batch 200, Loss: 1.51\n","Epoch 13/50, Batch 300, Loss: 1.53\n","Epoch 13/50, Batch 400, Loss: 1.56\n","Epoch 13/50, Batch 500, Loss: 1.56\n","Epoch 13/50, Batch 600, Loss: 1.53\n","Epoch 13/50, Batch 700, Loss: 1.57\n","Epoch 13/50, Batch 800, Loss: 1.53\n","Epoch 13/50, Batch 900, Loss: 1.62\n","Epoch 14/50, Batch 100, Loss: 1.56\n","Epoch 14/50, Batch 200, Loss: 1.56\n","Epoch 14/50, Batch 300, Loss: 1.67\n","Epoch 14/50, Batch 400, Loss: 1.57\n","Epoch 14/50, Batch 500, Loss: 1.52\n","Epoch 14/50, Batch 600, Loss: 1.53\n","Epoch 14/50, Batch 700, Loss: 1.56\n","Epoch 14/50, Batch 800, Loss: 1.53\n","Epoch 14/50, Batch 900, Loss: 1.56\n","Epoch 15/50, Batch 100, Loss: 1.57\n","Epoch 15/50, Batch 200, Loss: 1.60\n","Epoch 15/50, Batch 300, Loss: 1.60\n","Epoch 15/50, Batch 400, Loss: 1.53\n","Epoch 15/50, Batch 500, Loss: 1.57\n","Epoch 15/50, Batch 600, Loss: 1.57\n","Epoch 15/50, Batch 700, Loss: 1.57\n","Epoch 15/50, Batch 800, Loss: 1.58\n","Epoch 15/50, Batch 900, Loss: 1.64\n","Epoch 16/50, Batch 100, Loss: 1.52\n","Epoch 16/50, Batch 200, Loss: 1.55\n","Epoch 16/50, Batch 300, Loss: 1.54\n","Epoch 16/50, Batch 400, Loss: 1.58\n","Epoch 16/50, Batch 500, Loss: 1.57\n","Epoch 16/50, Batch 600, Loss: 1.60\n","Epoch 16/50, Batch 700, Loss: 1.62\n","Epoch 16/50, Batch 800, Loss: 1.52\n","Epoch 16/50, Batch 900, Loss: 1.59\n","Epoch 17/50, Batch 100, Loss: 1.53\n","Epoch 17/50, Batch 200, Loss: 1.49\n","Epoch 17/50, Batch 300, Loss: 1.59\n","Epoch 17/50, Batch 400, Loss: 1.53\n","Epoch 17/50, Batch 500, Loss: 1.63\n","Epoch 17/50, Batch 600, Loss: 1.55\n","Epoch 17/50, Batch 700, Loss: 1.54\n","Epoch 17/50, Batch 800, Loss: 1.60\n","Epoch 17/50, Batch 900, Loss: 1.50\n","Epoch 18/50, Batch 100, Loss: 1.50\n","Epoch 18/50, Batch 200, Loss: 1.56\n","Epoch 18/50, Batch 300, Loss: 1.54\n","Epoch 18/50, Batch 400, Loss: 1.65\n","Epoch 18/50, Batch 500, Loss: 1.62\n","Epoch 18/50, Batch 600, Loss: 1.53\n","Epoch 18/50, Batch 700, Loss: 1.50\n","Epoch 18/50, Batch 800, Loss: 1.57\n","Epoch 18/50, Batch 900, Loss: 1.64\n","Epoch 19/50, Batch 100, Loss: 1.53\n","Epoch 19/50, Batch 200, Loss: 1.55\n","Epoch 19/50, Batch 300, Loss: 1.56\n","Epoch 19/50, Batch 400, Loss: 1.55\n","Epoch 19/50, Batch 500, Loss: 1.56\n","Epoch 19/50, Batch 600, Loss: 1.55\n","Epoch 19/50, Batch 700, Loss: 1.54\n","Epoch 19/50, Batch 800, Loss: 1.52\n","Epoch 19/50, Batch 900, Loss: 1.55\n","Epoch 20/50, Batch 100, Loss: 1.60\n","Epoch 20/50, Batch 200, Loss: 1.56\n","Epoch 20/50, Batch 300, Loss: 1.57\n","Epoch 20/50, Batch 400, Loss: 1.55\n","Epoch 20/50, Batch 500, Loss: 1.52\n","Epoch 20/50, Batch 600, Loss: 1.60\n","Epoch 20/50, Batch 700, Loss: 1.57\n","Epoch 20/50, Batch 800, Loss: 1.56\n","Epoch 20/50, Batch 900, Loss: 1.59\n","Epoch 21/50, Batch 100, Loss: 1.55\n","Epoch 21/50, Batch 200, Loss: 1.56\n","Epoch 21/50, Batch 300, Loss: 1.54\n","Epoch 21/50, Batch 400, Loss: 1.55\n","Epoch 21/50, Batch 500, Loss: 1.56\n","Epoch 21/50, Batch 600, Loss: 1.55\n","Epoch 21/50, Batch 700, Loss: 1.53\n","Epoch 21/50, Batch 800, Loss: 1.56\n","Epoch 21/50, Batch 900, Loss: 1.51\n","Epoch 22/50, Batch 100, Loss: 1.53\n","Epoch 22/50, Batch 200, Loss: 1.52\n","Epoch 22/50, Batch 300, Loss: 1.51\n","Epoch 22/50, Batch 400, Loss: 1.54\n","Epoch 22/50, Batch 500, Loss: 1.56\n","Epoch 22/50, Batch 600, Loss: 1.58\n","Epoch 22/50, Batch 700, Loss: 1.59\n","Epoch 22/50, Batch 800, Loss: 1.54\n","Epoch 22/50, Batch 900, Loss: 1.60\n","Epoch 23/50, Batch 100, Loss: 1.52\n","Epoch 23/50, Batch 200, Loss: 1.54\n","Epoch 23/50, Batch 300, Loss: 1.54\n","Epoch 23/50, Batch 400, Loss: 1.62\n","Epoch 23/50, Batch 500, Loss: 1.56\n","Epoch 23/50, Batch 600, Loss: 1.62\n","Epoch 23/50, Batch 700, Loss: 1.56\n","Epoch 23/50, Batch 800, Loss: 1.59\n","Epoch 23/50, Batch 900, Loss: 1.53\n","Epoch 24/50, Batch 100, Loss: 1.56\n","Epoch 24/50, Batch 200, Loss: 1.50\n","Epoch 24/50, Batch 300, Loss: 1.62\n","Epoch 24/50, Batch 400, Loss: 1.59\n","Epoch 24/50, Batch 500, Loss: 1.50\n","Epoch 24/50, Batch 600, Loss: 1.55\n","Epoch 24/50, Batch 700, Loss: 1.54\n","Epoch 24/50, Batch 800, Loss: 1.57\n","Epoch 24/50, Batch 900, Loss: 1.54\n","Epoch 25/50, Batch 100, Loss: 1.55\n","Epoch 25/50, Batch 200, Loss: 1.57\n","Epoch 25/50, Batch 300, Loss: 1.51\n","Epoch 25/50, Batch 400, Loss: 1.61\n","Epoch 25/50, Batch 500, Loss: 1.53\n","Epoch 25/50, Batch 600, Loss: 1.55\n","Epoch 25/50, Batch 700, Loss: 1.51\n","Epoch 25/50, Batch 800, Loss: 1.54\n","Epoch 25/50, Batch 900, Loss: 1.52\n","Epoch 26/50, Batch 100, Loss: 1.51\n","Epoch 26/50, Batch 200, Loss: 1.52\n","Epoch 26/50, Batch 300, Loss: 1.55\n","Epoch 26/50, Batch 400, Loss: 1.55\n","Epoch 26/50, Batch 500, Loss: 1.50\n","Epoch 26/50, Batch 600, Loss: 1.60\n","Epoch 26/50, Batch 700, Loss: 1.57\n","Epoch 26/50, Batch 800, Loss: 1.53\n","Epoch 26/50, Batch 900, Loss: 1.54\n","Epoch 27/50, Batch 100, Loss: 1.58\n","Epoch 27/50, Batch 200, Loss: 1.64\n","Epoch 27/50, Batch 300, Loss: 1.60\n","Epoch 27/50, Batch 400, Loss: 1.56\n","Epoch 27/50, Batch 500, Loss: 1.54\n","Epoch 27/50, Batch 600, Loss: 1.57\n","Epoch 27/50, Batch 700, Loss: 1.59\n","Epoch 27/50, Batch 800, Loss: 1.53\n","Epoch 27/50, Batch 900, Loss: 1.55\n","Epoch 28/50, Batch 100, Loss: 1.48\n","Epoch 28/50, Batch 200, Loss: 1.55\n","Epoch 28/50, Batch 300, Loss: 1.56\n","Epoch 28/50, Batch 400, Loss: 1.52\n","Epoch 28/50, Batch 500, Loss: 1.61\n","Epoch 28/50, Batch 600, Loss: 1.53\n","Epoch 28/50, Batch 700, Loss: 1.50\n","Epoch 28/50, Batch 800, Loss: 1.52\n","Epoch 28/50, Batch 900, Loss: 1.55\n","Epoch 29/50, Batch 100, Loss: 1.55\n","Epoch 29/50, Batch 200, Loss: 1.50\n","Epoch 29/50, Batch 300, Loss: 1.54\n","Epoch 29/50, Batch 400, Loss: 1.51\n","Epoch 29/50, Batch 500, Loss: 1.51\n","Epoch 29/50, Batch 600, Loss: 1.55\n","Epoch 29/50, Batch 700, Loss: 1.55\n","Epoch 29/50, Batch 800, Loss: 1.49\n","Epoch 29/50, Batch 900, Loss: 1.56\n","Epoch 30/50, Batch 100, Loss: 1.56\n","Epoch 30/50, Batch 200, Loss: 1.56\n","Epoch 30/50, Batch 300, Loss: 1.50\n","Epoch 30/50, Batch 400, Loss: 1.58\n","Epoch 30/50, Batch 500, Loss: 1.58\n","Epoch 30/50, Batch 600, Loss: 1.56\n","Epoch 30/50, Batch 700, Loss: 1.52\n","Epoch 30/50, Batch 800, Loss: 1.61\n","Epoch 30/50, Batch 900, Loss: 1.60\n","Epoch 31/50, Batch 100, Loss: 1.51\n","Epoch 31/50, Batch 200, Loss: 1.53\n","Epoch 31/50, Batch 300, Loss: 1.49\n","Epoch 31/50, Batch 400, Loss: 1.59\n","Epoch 31/50, Batch 500, Loss: 1.59\n","Epoch 31/50, Batch 600, Loss: 1.59\n","Epoch 31/50, Batch 700, Loss: 1.59\n","Epoch 31/50, Batch 800, Loss: 1.55\n","Epoch 31/50, Batch 900, Loss: 1.57\n","Epoch 32/50, Batch 100, Loss: 1.56\n","Epoch 32/50, Batch 200, Loss: 1.57\n","Epoch 32/50, Batch 300, Loss: 1.49\n","Epoch 32/50, Batch 400, Loss: 1.50\n","Epoch 32/50, Batch 500, Loss: 1.54\n","Epoch 32/50, Batch 600, Loss: 1.59\n","Epoch 32/50, Batch 700, Loss: 1.55\n","Epoch 32/50, Batch 800, Loss: 1.59\n","Epoch 32/50, Batch 900, Loss: 1.50\n","Epoch 33/50, Batch 100, Loss: 1.54\n","Epoch 33/50, Batch 200, Loss: 1.53\n","Epoch 33/50, Batch 300, Loss: 1.58\n","Epoch 33/50, Batch 400, Loss: 1.51\n","Epoch 33/50, Batch 500, Loss: 1.52\n","Epoch 33/50, Batch 600, Loss: 1.56\n","Epoch 33/50, Batch 700, Loss: 1.53\n","Epoch 33/50, Batch 800, Loss: 1.50\n","Epoch 33/50, Batch 900, Loss: 1.54\n","Epoch 34/50, Batch 100, Loss: 1.56\n","Epoch 34/50, Batch 200, Loss: 1.51\n","Epoch 34/50, Batch 300, Loss: 1.47\n","Epoch 34/50, Batch 400, Loss: 1.50\n","Epoch 34/50, Batch 500, Loss: 1.54\n","Epoch 34/50, Batch 600, Loss: 1.57\n","Epoch 34/50, Batch 700, Loss: 1.53\n","Epoch 34/50, Batch 800, Loss: 1.53\n","Epoch 34/50, Batch 900, Loss: 1.51\n","Epoch 35/50, Batch 100, Loss: 1.50\n","Epoch 35/50, Batch 200, Loss: 1.51\n","Epoch 35/50, Batch 300, Loss: 1.58\n","Epoch 35/50, Batch 400, Loss: 1.59\n","Epoch 35/50, Batch 500, Loss: 1.49\n","Epoch 35/50, Batch 600, Loss: 1.54\n","Epoch 35/50, Batch 700, Loss: 1.53\n","Epoch 35/50, Batch 800, Loss: 1.53\n","Epoch 35/50, Batch 900, Loss: 1.55\n","Epoch 36/50, Batch 100, Loss: 1.51\n","Epoch 36/50, Batch 200, Loss: 1.48\n","Epoch 36/50, Batch 300, Loss: 1.51\n","Epoch 36/50, Batch 400, Loss: 1.62\n","Epoch 36/50, Batch 500, Loss: 1.53\n","Epoch 36/50, Batch 600, Loss: 1.49\n","Epoch 36/50, Batch 700, Loss: 1.52\n","Epoch 36/50, Batch 800, Loss: 1.52\n","Epoch 36/50, Batch 900, Loss: 1.52\n","Epoch 37/50, Batch 100, Loss: 1.50\n","Epoch 37/50, Batch 200, Loss: 1.53\n","Epoch 37/50, Batch 300, Loss: 1.54\n","Epoch 37/50, Batch 400, Loss: 1.51\n","Epoch 37/50, Batch 500, Loss: 1.51\n","Epoch 37/50, Batch 600, Loss: 1.54\n","Epoch 37/50, Batch 700, Loss: 1.57\n","Epoch 37/50, Batch 800, Loss: 1.54\n","Epoch 37/50, Batch 900, Loss: 1.52\n","Epoch 38/50, Batch 100, Loss: 1.52\n","Epoch 38/50, Batch 200, Loss: 1.49\n","Epoch 38/50, Batch 300, Loss: 1.56\n","Epoch 38/50, Batch 400, Loss: 1.50\n","Epoch 38/50, Batch 500, Loss: 1.59\n","Epoch 38/50, Batch 600, Loss: 1.53\n","Epoch 38/50, Batch 700, Loss: 1.48\n","Epoch 38/50, Batch 800, Loss: 1.50\n","Epoch 38/50, Batch 900, Loss: 1.53\n","Epoch 39/50, Batch 100, Loss: 1.56\n","Epoch 39/50, Batch 200, Loss: 1.52\n","Epoch 39/50, Batch 300, Loss: 1.53\n","Epoch 39/50, Batch 400, Loss: 1.49\n","Epoch 39/50, Batch 500, Loss: 1.51\n","Epoch 39/50, Batch 600, Loss: 1.52\n","Epoch 39/50, Batch 700, Loss: 1.51\n","Epoch 39/50, Batch 800, Loss: 1.57\n","Epoch 39/50, Batch 900, Loss: 1.53\n","Epoch 40/50, Batch 100, Loss: 1.55\n","Epoch 40/50, Batch 200, Loss: 1.61\n","Epoch 40/50, Batch 300, Loss: 1.51\n","Epoch 40/50, Batch 400, Loss: 1.54\n","Epoch 40/50, Batch 500, Loss: 1.51\n","Epoch 40/50, Batch 600, Loss: 1.48\n","Epoch 40/50, Batch 700, Loss: 1.56\n","Epoch 40/50, Batch 800, Loss: 1.53\n","Epoch 40/50, Batch 900, Loss: 1.51\n","Epoch 41/50, Batch 100, Loss: 1.59\n","Epoch 41/50, Batch 200, Loss: 1.52\n","Epoch 41/50, Batch 300, Loss: 1.56\n","Epoch 41/50, Batch 400, Loss: 1.53\n","Epoch 41/50, Batch 500, Loss: 1.56\n","Epoch 41/50, Batch 600, Loss: 1.57\n","Epoch 41/50, Batch 700, Loss: 1.51\n","Epoch 41/50, Batch 800, Loss: 1.52\n","Epoch 41/50, Batch 900, Loss: 1.49\n","Epoch 42/50, Batch 100, Loss: 1.58\n","Epoch 42/50, Batch 200, Loss: 1.55\n","Epoch 42/50, Batch 300, Loss: 1.50\n","Epoch 42/50, Batch 400, Loss: 1.54\n","Epoch 42/50, Batch 500, Loss: 1.50\n","Epoch 42/50, Batch 600, Loss: 1.57\n","Epoch 42/50, Batch 700, Loss: 1.51\n","Epoch 42/50, Batch 800, Loss: 1.56\n","Epoch 42/50, Batch 900, Loss: 1.47\n","Epoch 43/50, Batch 100, Loss: 1.52\n","Epoch 43/50, Batch 200, Loss: 1.51\n","Epoch 43/50, Batch 300, Loss: 1.52\n","Epoch 43/50, Batch 400, Loss: 1.48\n","Epoch 43/50, Batch 500, Loss: 1.52\n","Epoch 43/50, Batch 600, Loss: 1.51\n","Epoch 43/50, Batch 700, Loss: 1.51\n","Epoch 43/50, Batch 800, Loss: 1.58\n","Epoch 43/50, Batch 900, Loss: 1.53\n","Epoch 44/50, Batch 100, Loss: 1.55\n","Epoch 44/50, Batch 200, Loss: 1.52\n","Epoch 44/50, Batch 300, Loss: 1.51\n","Epoch 44/50, Batch 400, Loss: 1.49\n","Epoch 44/50, Batch 500, Loss: 1.52\n","Epoch 44/50, Batch 600, Loss: 1.56\n","Epoch 44/50, Batch 700, Loss: 1.54\n","Epoch 44/50, Batch 800, Loss: 1.51\n","Epoch 44/50, Batch 900, Loss: 1.56\n","Epoch 45/50, Batch 100, Loss: 1.53\n","Epoch 45/50, Batch 200, Loss: 1.56\n","Epoch 45/50, Batch 300, Loss: 1.54\n","Epoch 45/50, Batch 400, Loss: 1.67\n","Epoch 45/50, Batch 500, Loss: 1.54\n","Epoch 45/50, Batch 600, Loss: 1.46\n","Epoch 45/50, Batch 700, Loss: 1.58\n","Epoch 45/50, Batch 800, Loss: 1.51\n","Epoch 45/50, Batch 900, Loss: 1.57\n","Epoch 46/50, Batch 100, Loss: 1.56\n","Epoch 46/50, Batch 200, Loss: 1.52\n","Epoch 46/50, Batch 300, Loss: 1.50\n","Epoch 46/50, Batch 400, Loss: 1.53\n","Epoch 46/50, Batch 500, Loss: 1.61\n","Epoch 46/50, Batch 600, Loss: 1.52\n","Epoch 46/50, Batch 700, Loss: 1.49\n","Epoch 46/50, Batch 800, Loss: 1.50\n","Epoch 46/50, Batch 900, Loss: 1.54\n","Epoch 47/50, Batch 100, Loss: 1.55\n","Epoch 47/50, Batch 200, Loss: 1.53\n","Epoch 47/50, Batch 300, Loss: 1.49\n","Epoch 47/50, Batch 400, Loss: 1.51\n","Epoch 47/50, Batch 500, Loss: 1.50\n","Epoch 47/50, Batch 600, Loss: 1.53\n","Epoch 47/50, Batch 700, Loss: 1.51\n","Epoch 47/50, Batch 800, Loss: 1.51\n","Epoch 47/50, Batch 900, Loss: 1.52\n","Epoch 48/50, Batch 100, Loss: 1.50\n","Epoch 48/50, Batch 200, Loss: 1.51\n","Epoch 48/50, Batch 300, Loss: 1.55\n","Epoch 48/50, Batch 400, Loss: 1.55\n","Epoch 48/50, Batch 500, Loss: 1.56\n","Epoch 48/50, Batch 600, Loss: 1.52\n","Epoch 48/50, Batch 700, Loss: 1.50\n","Epoch 48/50, Batch 800, Loss: 1.50\n","Epoch 48/50, Batch 900, Loss: 1.55\n","Epoch 49/50, Batch 100, Loss: 1.48\n","Epoch 49/50, Batch 200, Loss: 1.55\n","Epoch 49/50, Batch 300, Loss: 1.51\n","Epoch 49/50, Batch 400, Loss: 1.58\n","Epoch 49/50, Batch 500, Loss: 1.51\n","Epoch 49/50, Batch 600, Loss: 1.52\n","Epoch 49/50, Batch 700, Loss: 1.52\n","Epoch 49/50, Batch 800, Loss: 1.52\n","Epoch 49/50, Batch 900, Loss: 1.53\n","Epoch 50/50, Batch 100, Loss: 1.51\n","Epoch 50/50, Batch 200, Loss: 1.50\n","Epoch 50/50, Batch 300, Loss: 1.51\n","Epoch 50/50, Batch 400, Loss: 1.58\n","Epoch 50/50, Batch 500, Loss: 1.50\n","Epoch 50/50, Batch 600, Loss: 1.49\n","Epoch 50/50, Batch 700, Loss: 1.53\n","Epoch 50/50, Batch 800, Loss: 1.54\n","Epoch 50/50, Batch 900, Loss: 1.58\n"]}]},{"cell_type":"markdown","source":["## Performance Evaluation"],"metadata":{"id":"xt0RBUixiprY"}},{"cell_type":"code","source":["def get_accracy(loader, model):\n","  if loader.dataset.train:\n","    print('Getting accuracy on training data.')\n","  else:\n","    print('Getting accuracy on testing data.')\n","  \n","  n_corrects = 0\n","  n_samples = 0\n","  model.eval()\n","\n","  with torch.no_grad():\n","    for x,y in loader:\n","      x = x.to(device)\n","      y = y.to(device)\n","\n","      scores = model(x)\n","      _,y_pred = scores.max(1)\n","      n_corrects += (y_pred == y).sum()\n","      n_samples += y_pred.size(0)\n","\n","    print(f'We got {n_corrects}/{n_samples} correct. Accuracy = {float(n_corrects)/float(n_samples)* 100.0:.2f}')\n","  model.train()"],"metadata":{"id":"_2s3A6tKius1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_accracy(train_loader,model)\n","get_accracy(test_loader, model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IEEXlTleiwGj","executionInfo":{"status":"ok","timestamp":1639279096737,"user_tz":-420,"elapsed":15299,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"outputId":"539ce16d-43d1-4d9d-c015-c07cf6cd4834"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Getting accuracy on training data.\n","We got 56185/60000 correct. Accuracy = 93.64\n","Getting accuracy on testing data.\n","We got 8820/10000 correct. Accuracy = 88.20\n"]}]},{"cell_type":"markdown","source":["# CIFAR10 using MLP model"],"metadata":{"id":"XB34aUeomJ2l"}},{"cell_type":"markdown","source":["## Import nescessary libraries"],"metadata":{"id":"rDpvd8jCnCUc"}},{"cell_type":"code","source":["# Import nescessary libraries\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Build model\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# Training strategy\n","import torch.optim as optim\n","# Split data\n","from torch.utils.data import DataLoader\n","# Load data\n","import torchvision.datasets as datasets\n","# Data preprocessing\n","import torchvision.transforms as transforms"],"metadata":{"id":"aExIwJNdmSoB","executionInfo":{"status":"ok","timestamp":1639292361834,"user_tz":-420,"elapsed":424,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["## Check 'CPU' or 'GPU'"],"metadata":{"id":"5XIEEuG-nM7o"}},{"cell_type":"code","source":["# Check whether we are using 'GPU' or 'CPU'\n","device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f2TBV9uJmSli","executionInfo":{"status":"ok","timestamp":1639292364945,"user_tz":-420,"elapsed":436,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"outputId":"752cedd9-ae0f-4fad-9934-95400888faf6"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["# Setup for getting the reproducible results\n","\n","random.seed(1)\n","np.random.seed(1)\n","torch.manual_seed(1)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"],"metadata":{"id":"Dtf1MSYMmSi9","executionInfo":{"status":"ok","timestamp":1639292367732,"user_tz":-420,"elapsed":417,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# USE CIFAR10 DATASET\n","# setup hyperparameters\n","input_size = 3072 #  3*32*32\n","n_classes = 10 # 10 class 0,...,9\n","learning_rate = 0.001 # learning rate on gradient descent\n","batch_size = 64 # the number of samples in each batch\n","n_epochs = 50 # the number of training epochs"],"metadata":{"id":"hDEjgeldmSci","executionInfo":{"status":"ok","timestamp":1639292513328,"user_tz":-420,"elapsed":408,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["## Prepare CIFAR10 dataset"],"metadata":{"id":"KUxC_SKJnoug"}},{"cell_type":"code","source":["# LOAD data from Google Drive\n","# Load 'CIFAR10' dataset\n","train_dataset = datasets.CIFAR10(root='/content/drive/MyDrive/10. Toán cho KHMT/datasets' , train =True,\n","                              transform=transforms.ToTensor(), download=True)\n","train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,shuffle=True)\n","test_dataset = datasets.CIFAR10(root='/content/drive/MyDrive/10. Toán cho KHMT/datasets' ,train=False,transform=transforms.ToTensor(),\n","                              download=True)\n","test_loader = DataLoader(dataset= test_dataset, batch_size=batch_size, shuffle=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wBoFfIZfmSTl","executionInfo":{"status":"ok","timestamp":1639292377964,"user_tz":-420,"elapsed":2636,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"outputId":"6b052322-535e-4e85-e6ca-234ca8c07cf8"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["# Show an image example in training set\n","classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","image, label = train_dataset[1]\n","plt.imshow(image.permute((1,2,0)), cmap='gray')\n","print(label)\n","print(classes[label])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"id":"dJysSqNGs0n3","executionInfo":{"status":"ok","timestamp":1639291061725,"user_tz":-420,"elapsed":9,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"outputId":"a2afbb57-1a8f-4a75-ddac-bba40fd046c2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["9\n","truck\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["## Build MLP model"],"metadata":{"id":"rKv_QKFlpC7d"}},{"cell_type":"code","source":["#Build a MLP model by using Pytorch\n","#Approach 2\n","class MLP(nn.Module):\n","    def __init__(self, input_size, n_classes):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(input_size, 1024), nn.ReLU(), #Input layer\n","            nn.Linear(1024, 512), nn.ReLU(), #Hidden Layer 1 \n","            nn.Linear(512, 256), nn.ReLU(), #Hidden Layer 2\n","            nn.Linear(256, 64), nn.ReLU(), #Hidden Layer 3 \n","            nn.Linear(64, n_classes), nn.Softmax(dim =1), #Output Layer 3 \n","        )\n","    def forward(self, X):\n","        prob = self.model(X)\n","        return prob"],"metadata":{"id":"o09ggg3gq6jS","executionInfo":{"status":"ok","timestamp":1639292518468,"user_tz":-420,"elapsed":534,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["#Build a MLP model by using Pytorch\n","model = MLP(input_size=input_size, n_classes=n_classes).to(device)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aJjyDemuq7FE","executionInfo":{"status":"ok","timestamp":1639292520936,"user_tz":-420,"elapsed":429,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"outputId":"dfaff7b4-ebb8-4610-a2bb-9bdfa8c93d62"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["MLP(\n","  (model): Sequential(\n","    (0): Linear(in_features=3072, out_features=1024, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=1024, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=256, bias=True)\n","    (5): ReLU()\n","    (6): Linear(in_features=256, out_features=64, bias=True)\n","    (7): ReLU()\n","    (8): Linear(in_features=64, out_features=10, bias=True)\n","    (9): Softmax(dim=1)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["#Define the loss and the optimization algorithm\n","criterion = nn.CrossEntropyLoss() # Loss function: Cross entropy\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate) # Optimizer: Adam"],"metadata":{"id":"qgM29_m6XVl3","executionInfo":{"status":"ok","timestamp":1639292524719,"user_tz":-420,"elapsed":411,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}}},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":["## Training model"],"metadata":{"id":"zSFuJQK_pHIa"}},{"cell_type":"code","source":["#Training model\n","for epoch in range(n_epochs):\n","  for batch_idx, (data, targets) in enumerate(train_loader):\n","    # Get data to GPU\n","    data = data.to(device) # Put our images to the GPU if GPU is available\n","    targets = targets.to(device) # Put our labels to the GPU as well\n","\n","    # Chage to the correct tensor shape\n","    data = data.reshape(data.shape[0],-1)\n","\n","    # forward pass\n","    scores = model(data)\n","    loss = criterion(scores, targets) # Compute the loss/cost function 3 for this batch\n","\n","    # backward pass\n","    optimizer.zero_grad() # empty the optimizer first\n","    loss.backward() # compute gradient dJ/dw's\n","\n","    # Gradient descent\n","    optimizer.step()\n","    \n","    if (batch_idx+1)%100 == 0:\n","      print(f'Epoch {epoch+1}/{n_epochs}, Batch {batch_idx+1}, Loss: {loss.item():.2f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x0nTZ-ndrYQx","executionInfo":{"status":"ok","timestamp":1639293051445,"user_tz":-420,"elapsed":524477,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"outputId":"76c2d5f8-3f00-4021-9444-c0763b461ed5"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50, Batch 100, Loss: 2.27\n","Epoch 1/50, Batch 200, Loss: 2.26\n","Epoch 1/50, Batch 300, Loss: 2.22\n","Epoch 1/50, Batch 400, Loss: 2.22\n","Epoch 1/50, Batch 500, Loss: 2.19\n","Epoch 1/50, Batch 600, Loss: 2.18\n","Epoch 1/50, Batch 700, Loss: 2.21\n","Epoch 2/50, Batch 100, Loss: 2.18\n","Epoch 2/50, Batch 200, Loss: 2.14\n","Epoch 2/50, Batch 300, Loss: 2.11\n","Epoch 2/50, Batch 400, Loss: 2.19\n","Epoch 2/50, Batch 500, Loss: 2.09\n","Epoch 2/50, Batch 600, Loss: 2.11\n","Epoch 2/50, Batch 700, Loss: 2.10\n","Epoch 3/50, Batch 100, Loss: 2.14\n","Epoch 3/50, Batch 200, Loss: 2.12\n","Epoch 3/50, Batch 300, Loss: 2.18\n","Epoch 3/50, Batch 400, Loss: 2.19\n","Epoch 3/50, Batch 500, Loss: 2.08\n","Epoch 3/50, Batch 600, Loss: 2.14\n","Epoch 3/50, Batch 700, Loss: 2.15\n","Epoch 4/50, Batch 100, Loss: 2.06\n","Epoch 4/50, Batch 200, Loss: 2.15\n","Epoch 4/50, Batch 300, Loss: 2.08\n","Epoch 4/50, Batch 400, Loss: 2.06\n","Epoch 4/50, Batch 500, Loss: 2.12\n","Epoch 4/50, Batch 600, Loss: 2.10\n","Epoch 4/50, Batch 700, Loss: 2.15\n","Epoch 5/50, Batch 100, Loss: 2.08\n","Epoch 5/50, Batch 200, Loss: 2.18\n","Epoch 5/50, Batch 300, Loss: 2.16\n","Epoch 5/50, Batch 400, Loss: 2.10\n","Epoch 5/50, Batch 500, Loss: 2.12\n","Epoch 5/50, Batch 600, Loss: 2.01\n","Epoch 5/50, Batch 700, Loss: 2.09\n","Epoch 6/50, Batch 100, Loss: 2.17\n","Epoch 6/50, Batch 200, Loss: 2.16\n","Epoch 6/50, Batch 300, Loss: 2.08\n","Epoch 6/50, Batch 400, Loss: 2.10\n","Epoch 6/50, Batch 500, Loss: 2.09\n","Epoch 6/50, Batch 600, Loss: 2.12\n","Epoch 6/50, Batch 700, Loss: 2.13\n","Epoch 7/50, Batch 100, Loss: 2.03\n","Epoch 7/50, Batch 200, Loss: 1.98\n","Epoch 7/50, Batch 300, Loss: 2.15\n","Epoch 7/50, Batch 400, Loss: 2.08\n","Epoch 7/50, Batch 500, Loss: 2.00\n","Epoch 7/50, Batch 600, Loss: 2.01\n","Epoch 7/50, Batch 700, Loss: 2.03\n","Epoch 8/50, Batch 100, Loss: 2.21\n","Epoch 8/50, Batch 200, Loss: 2.10\n","Epoch 8/50, Batch 300, Loss: 2.03\n","Epoch 8/50, Batch 400, Loss: 2.02\n","Epoch 8/50, Batch 500, Loss: 2.10\n","Epoch 8/50, Batch 600, Loss: 2.09\n","Epoch 8/50, Batch 700, Loss: 1.99\n","Epoch 9/50, Batch 100, Loss: 1.99\n","Epoch 9/50, Batch 200, Loss: 2.10\n","Epoch 9/50, Batch 300, Loss: 2.06\n","Epoch 9/50, Batch 400, Loss: 2.08\n","Epoch 9/50, Batch 500, Loss: 1.96\n","Epoch 9/50, Batch 600, Loss: 2.10\n","Epoch 9/50, Batch 700, Loss: 2.10\n","Epoch 10/50, Batch 100, Loss: 2.00\n","Epoch 10/50, Batch 200, Loss: 2.09\n","Epoch 10/50, Batch 300, Loss: 2.15\n","Epoch 10/50, Batch 400, Loss: 2.05\n","Epoch 10/50, Batch 500, Loss: 2.09\n","Epoch 10/50, Batch 600, Loss: 2.06\n","Epoch 10/50, Batch 700, Loss: 2.08\n","Epoch 11/50, Batch 100, Loss: 2.06\n","Epoch 11/50, Batch 200, Loss: 2.14\n","Epoch 11/50, Batch 300, Loss: 1.96\n","Epoch 11/50, Batch 400, Loss: 2.09\n","Epoch 11/50, Batch 500, Loss: 2.02\n","Epoch 11/50, Batch 600, Loss: 2.11\n","Epoch 11/50, Batch 700, Loss: 2.15\n","Epoch 12/50, Batch 100, Loss: 2.03\n","Epoch 12/50, Batch 200, Loss: 2.05\n","Epoch 12/50, Batch 300, Loss: 2.12\n","Epoch 12/50, Batch 400, Loss: 2.14\n","Epoch 12/50, Batch 500, Loss: 1.93\n","Epoch 12/50, Batch 600, Loss: 2.17\n","Epoch 12/50, Batch 700, Loss: 2.10\n","Epoch 13/50, Batch 100, Loss: 2.10\n","Epoch 13/50, Batch 200, Loss: 2.05\n","Epoch 13/50, Batch 300, Loss: 2.06\n","Epoch 13/50, Batch 400, Loss: 2.06\n","Epoch 13/50, Batch 500, Loss: 1.96\n","Epoch 13/50, Batch 600, Loss: 1.98\n","Epoch 13/50, Batch 700, Loss: 2.16\n","Epoch 14/50, Batch 100, Loss: 2.14\n","Epoch 14/50, Batch 200, Loss: 2.12\n","Epoch 14/50, Batch 300, Loss: 2.11\n","Epoch 14/50, Batch 400, Loss: 2.01\n","Epoch 14/50, Batch 500, Loss: 2.09\n","Epoch 14/50, Batch 600, Loss: 2.03\n","Epoch 14/50, Batch 700, Loss: 2.09\n","Epoch 15/50, Batch 100, Loss: 2.05\n","Epoch 15/50, Batch 200, Loss: 2.01\n","Epoch 15/50, Batch 300, Loss: 2.00\n","Epoch 15/50, Batch 400, Loss: 2.06\n","Epoch 15/50, Batch 500, Loss: 2.09\n","Epoch 15/50, Batch 600, Loss: 1.99\n","Epoch 15/50, Batch 700, Loss: 2.08\n","Epoch 16/50, Batch 100, Loss: 2.06\n","Epoch 16/50, Batch 200, Loss: 2.13\n","Epoch 16/50, Batch 300, Loss: 2.03\n","Epoch 16/50, Batch 400, Loss: 2.05\n","Epoch 16/50, Batch 500, Loss: 2.09\n","Epoch 16/50, Batch 600, Loss: 2.11\n","Epoch 16/50, Batch 700, Loss: 2.07\n","Epoch 17/50, Batch 100, Loss: 2.09\n","Epoch 17/50, Batch 200, Loss: 2.02\n","Epoch 17/50, Batch 300, Loss: 2.00\n","Epoch 17/50, Batch 400, Loss: 2.16\n","Epoch 17/50, Batch 500, Loss: 1.98\n","Epoch 17/50, Batch 600, Loss: 1.98\n","Epoch 17/50, Batch 700, Loss: 2.08\n","Epoch 18/50, Batch 100, Loss: 2.06\n","Epoch 18/50, Batch 200, Loss: 2.10\n","Epoch 18/50, Batch 300, Loss: 2.07\n","Epoch 18/50, Batch 400, Loss: 2.04\n","Epoch 18/50, Batch 500, Loss: 1.99\n","Epoch 18/50, Batch 600, Loss: 2.01\n","Epoch 18/50, Batch 700, Loss: 1.99\n","Epoch 19/50, Batch 100, Loss: 1.98\n","Epoch 19/50, Batch 200, Loss: 2.00\n","Epoch 19/50, Batch 300, Loss: 2.01\n","Epoch 19/50, Batch 400, Loss: 2.08\n","Epoch 19/50, Batch 500, Loss: 1.99\n","Epoch 19/50, Batch 600, Loss: 1.97\n","Epoch 19/50, Batch 700, Loss: 2.14\n","Epoch 20/50, Batch 100, Loss: 2.08\n","Epoch 20/50, Batch 200, Loss: 1.97\n","Epoch 20/50, Batch 300, Loss: 2.05\n","Epoch 20/50, Batch 400, Loss: 1.99\n","Epoch 20/50, Batch 500, Loss: 2.06\n","Epoch 20/50, Batch 600, Loss: 1.94\n","Epoch 20/50, Batch 700, Loss: 2.03\n","Epoch 21/50, Batch 100, Loss: 2.07\n","Epoch 21/50, Batch 200, Loss: 1.92\n","Epoch 21/50, Batch 300, Loss: 2.03\n","Epoch 21/50, Batch 400, Loss: 2.01\n","Epoch 21/50, Batch 500, Loss: 2.05\n","Epoch 21/50, Batch 600, Loss: 1.98\n","Epoch 21/50, Batch 700, Loss: 2.05\n","Epoch 22/50, Batch 100, Loss: 2.16\n","Epoch 22/50, Batch 200, Loss: 2.00\n","Epoch 22/50, Batch 300, Loss: 1.99\n","Epoch 22/50, Batch 400, Loss: 2.06\n","Epoch 22/50, Batch 500, Loss: 2.03\n","Epoch 22/50, Batch 600, Loss: 2.04\n","Epoch 22/50, Batch 700, Loss: 2.12\n","Epoch 23/50, Batch 100, Loss: 2.00\n","Epoch 23/50, Batch 200, Loss: 2.05\n","Epoch 23/50, Batch 300, Loss: 1.91\n","Epoch 23/50, Batch 400, Loss: 2.04\n","Epoch 23/50, Batch 500, Loss: 2.11\n","Epoch 23/50, Batch 600, Loss: 2.05\n","Epoch 23/50, Batch 700, Loss: 2.01\n","Epoch 24/50, Batch 100, Loss: 2.02\n","Epoch 24/50, Batch 200, Loss: 1.98\n","Epoch 24/50, Batch 300, Loss: 2.12\n","Epoch 24/50, Batch 400, Loss: 1.98\n","Epoch 24/50, Batch 500, Loss: 2.10\n","Epoch 24/50, Batch 600, Loss: 1.96\n","Epoch 24/50, Batch 700, Loss: 2.02\n","Epoch 25/50, Batch 100, Loss: 2.00\n","Epoch 25/50, Batch 200, Loss: 1.99\n","Epoch 25/50, Batch 300, Loss: 2.00\n","Epoch 25/50, Batch 400, Loss: 1.95\n","Epoch 25/50, Batch 500, Loss: 2.02\n","Epoch 25/50, Batch 600, Loss: 2.10\n","Epoch 25/50, Batch 700, Loss: 2.04\n","Epoch 26/50, Batch 100, Loss: 2.01\n","Epoch 26/50, Batch 200, Loss: 1.93\n","Epoch 26/50, Batch 300, Loss: 1.97\n","Epoch 26/50, Batch 400, Loss: 2.02\n","Epoch 26/50, Batch 500, Loss: 2.04\n","Epoch 26/50, Batch 600, Loss: 1.92\n","Epoch 26/50, Batch 700, Loss: 2.01\n","Epoch 27/50, Batch 100, Loss: 2.03\n","Epoch 27/50, Batch 200, Loss: 1.95\n","Epoch 27/50, Batch 300, Loss: 2.13\n","Epoch 27/50, Batch 400, Loss: 2.15\n","Epoch 27/50, Batch 500, Loss: 2.00\n","Epoch 27/50, Batch 600, Loss: 2.07\n","Epoch 27/50, Batch 700, Loss: 1.91\n","Epoch 28/50, Batch 100, Loss: 1.98\n","Epoch 28/50, Batch 200, Loss: 1.98\n","Epoch 28/50, Batch 300, Loss: 2.00\n","Epoch 28/50, Batch 400, Loss: 2.02\n","Epoch 28/50, Batch 500, Loss: 2.09\n","Epoch 28/50, Batch 600, Loss: 2.00\n","Epoch 28/50, Batch 700, Loss: 2.13\n","Epoch 29/50, Batch 100, Loss: 2.13\n","Epoch 29/50, Batch 200, Loss: 2.06\n","Epoch 29/50, Batch 300, Loss: 2.04\n","Epoch 29/50, Batch 400, Loss: 2.01\n","Epoch 29/50, Batch 500, Loss: 2.03\n","Epoch 29/50, Batch 600, Loss: 2.02\n","Epoch 29/50, Batch 700, Loss: 2.01\n","Epoch 30/50, Batch 100, Loss: 2.10\n","Epoch 30/50, Batch 200, Loss: 2.01\n","Epoch 30/50, Batch 300, Loss: 2.03\n","Epoch 30/50, Batch 400, Loss: 2.07\n","Epoch 30/50, Batch 500, Loss: 1.93\n","Epoch 30/50, Batch 600, Loss: 2.01\n","Epoch 30/50, Batch 700, Loss: 1.98\n","Epoch 31/50, Batch 100, Loss: 2.03\n","Epoch 31/50, Batch 200, Loss: 2.04\n","Epoch 31/50, Batch 300, Loss: 2.12\n","Epoch 31/50, Batch 400, Loss: 1.86\n","Epoch 31/50, Batch 500, Loss: 2.06\n","Epoch 31/50, Batch 600, Loss: 1.98\n","Epoch 31/50, Batch 700, Loss: 2.00\n","Epoch 32/50, Batch 100, Loss: 2.08\n","Epoch 32/50, Batch 200, Loss: 2.07\n","Epoch 32/50, Batch 300, Loss: 1.92\n","Epoch 32/50, Batch 400, Loss: 2.10\n","Epoch 32/50, Batch 500, Loss: 2.00\n","Epoch 32/50, Batch 600, Loss: 2.04\n","Epoch 32/50, Batch 700, Loss: 2.01\n","Epoch 33/50, Batch 100, Loss: 2.01\n","Epoch 33/50, Batch 200, Loss: 2.09\n","Epoch 33/50, Batch 300, Loss: 1.92\n","Epoch 33/50, Batch 400, Loss: 2.10\n","Epoch 33/50, Batch 500, Loss: 2.09\n","Epoch 33/50, Batch 600, Loss: 2.09\n","Epoch 33/50, Batch 700, Loss: 1.93\n","Epoch 34/50, Batch 100, Loss: 1.99\n","Epoch 34/50, Batch 200, Loss: 1.99\n","Epoch 34/50, Batch 300, Loss: 2.07\n","Epoch 34/50, Batch 400, Loss: 2.04\n","Epoch 34/50, Batch 500, Loss: 1.93\n","Epoch 34/50, Batch 600, Loss: 1.98\n","Epoch 34/50, Batch 700, Loss: 1.87\n","Epoch 35/50, Batch 100, Loss: 2.12\n","Epoch 35/50, Batch 200, Loss: 2.01\n","Epoch 35/50, Batch 300, Loss: 2.10\n","Epoch 35/50, Batch 400, Loss: 2.06\n","Epoch 35/50, Batch 500, Loss: 2.05\n","Epoch 35/50, Batch 600, Loss: 2.05\n","Epoch 35/50, Batch 700, Loss: 1.93\n","Epoch 36/50, Batch 100, Loss: 2.04\n","Epoch 36/50, Batch 200, Loss: 2.07\n","Epoch 36/50, Batch 300, Loss: 2.01\n","Epoch 36/50, Batch 400, Loss: 1.99\n","Epoch 36/50, Batch 500, Loss: 2.08\n","Epoch 36/50, Batch 600, Loss: 2.09\n","Epoch 36/50, Batch 700, Loss: 2.05\n","Epoch 37/50, Batch 100, Loss: 2.00\n","Epoch 37/50, Batch 200, Loss: 2.09\n","Epoch 37/50, Batch 300, Loss: 2.01\n","Epoch 37/50, Batch 400, Loss: 1.96\n","Epoch 37/50, Batch 500, Loss: 1.93\n","Epoch 37/50, Batch 600, Loss: 2.05\n","Epoch 37/50, Batch 700, Loss: 2.01\n","Epoch 38/50, Batch 100, Loss: 2.05\n","Epoch 38/50, Batch 200, Loss: 1.99\n","Epoch 38/50, Batch 300, Loss: 2.07\n","Epoch 38/50, Batch 400, Loss: 1.99\n","Epoch 38/50, Batch 500, Loss: 2.01\n","Epoch 38/50, Batch 600, Loss: 1.94\n","Epoch 38/50, Batch 700, Loss: 1.94\n","Epoch 39/50, Batch 100, Loss: 2.01\n","Epoch 39/50, Batch 200, Loss: 2.02\n","Epoch 39/50, Batch 300, Loss: 1.93\n","Epoch 39/50, Batch 400, Loss: 2.13\n","Epoch 39/50, Batch 500, Loss: 2.06\n","Epoch 39/50, Batch 600, Loss: 2.10\n","Epoch 39/50, Batch 700, Loss: 1.97\n","Epoch 40/50, Batch 100, Loss: 2.04\n","Epoch 40/50, Batch 200, Loss: 2.01\n","Epoch 40/50, Batch 300, Loss: 1.99\n","Epoch 40/50, Batch 400, Loss: 2.01\n","Epoch 40/50, Batch 500, Loss: 1.96\n","Epoch 40/50, Batch 600, Loss: 2.03\n","Epoch 40/50, Batch 700, Loss: 1.97\n","Epoch 41/50, Batch 100, Loss: 2.00\n","Epoch 41/50, Batch 200, Loss: 2.10\n","Epoch 41/50, Batch 300, Loss: 1.96\n","Epoch 41/50, Batch 400, Loss: 2.01\n","Epoch 41/50, Batch 500, Loss: 1.93\n","Epoch 41/50, Batch 600, Loss: 2.03\n","Epoch 41/50, Batch 700, Loss: 2.10\n","Epoch 42/50, Batch 100, Loss: 2.09\n","Epoch 42/50, Batch 200, Loss: 1.98\n","Epoch 42/50, Batch 300, Loss: 1.98\n","Epoch 42/50, Batch 400, Loss: 2.11\n","Epoch 42/50, Batch 500, Loss: 1.97\n","Epoch 42/50, Batch 600, Loss: 2.02\n","Epoch 42/50, Batch 700, Loss: 2.17\n","Epoch 43/50, Batch 100, Loss: 1.85\n","Epoch 43/50, Batch 200, Loss: 2.08\n","Epoch 43/50, Batch 300, Loss: 2.06\n","Epoch 43/50, Batch 400, Loss: 1.96\n","Epoch 43/50, Batch 500, Loss: 2.06\n","Epoch 43/50, Batch 600, Loss: 2.07\n","Epoch 43/50, Batch 700, Loss: 1.99\n","Epoch 44/50, Batch 100, Loss: 1.95\n","Epoch 44/50, Batch 200, Loss: 2.10\n","Epoch 44/50, Batch 300, Loss: 1.96\n","Epoch 44/50, Batch 400, Loss: 2.03\n","Epoch 44/50, Batch 500, Loss: 2.00\n","Epoch 44/50, Batch 600, Loss: 2.03\n","Epoch 44/50, Batch 700, Loss: 2.07\n","Epoch 45/50, Batch 100, Loss: 2.09\n","Epoch 45/50, Batch 200, Loss: 2.12\n","Epoch 45/50, Batch 300, Loss: 2.06\n","Epoch 45/50, Batch 400, Loss: 1.97\n","Epoch 45/50, Batch 500, Loss: 1.95\n","Epoch 45/50, Batch 600, Loss: 2.06\n","Epoch 45/50, Batch 700, Loss: 2.07\n","Epoch 46/50, Batch 100, Loss: 2.00\n","Epoch 46/50, Batch 200, Loss: 1.97\n","Epoch 46/50, Batch 300, Loss: 1.98\n","Epoch 46/50, Batch 400, Loss: 2.04\n","Epoch 46/50, Batch 500, Loss: 2.12\n","Epoch 46/50, Batch 600, Loss: 2.08\n","Epoch 46/50, Batch 700, Loss: 2.03\n","Epoch 47/50, Batch 100, Loss: 2.00\n","Epoch 47/50, Batch 200, Loss: 2.02\n","Epoch 47/50, Batch 300, Loss: 1.98\n","Epoch 47/50, Batch 400, Loss: 2.04\n","Epoch 47/50, Batch 500, Loss: 1.96\n","Epoch 47/50, Batch 600, Loss: 2.06\n","Epoch 47/50, Batch 700, Loss: 1.94\n","Epoch 48/50, Batch 100, Loss: 2.03\n","Epoch 48/50, Batch 200, Loss: 2.06\n","Epoch 48/50, Batch 300, Loss: 2.04\n","Epoch 48/50, Batch 400, Loss: 1.97\n","Epoch 48/50, Batch 500, Loss: 2.02\n","Epoch 48/50, Batch 600, Loss: 1.88\n","Epoch 48/50, Batch 700, Loss: 2.06\n","Epoch 49/50, Batch 100, Loss: 2.06\n","Epoch 49/50, Batch 200, Loss: 2.01\n","Epoch 49/50, Batch 300, Loss: 2.01\n","Epoch 49/50, Batch 400, Loss: 2.11\n","Epoch 49/50, Batch 500, Loss: 2.06\n","Epoch 49/50, Batch 600, Loss: 1.99\n","Epoch 49/50, Batch 700, Loss: 2.04\n","Epoch 50/50, Batch 100, Loss: 2.01\n","Epoch 50/50, Batch 200, Loss: 2.02\n","Epoch 50/50, Batch 300, Loss: 2.05\n","Epoch 50/50, Batch 400, Loss: 2.00\n","Epoch 50/50, Batch 500, Loss: 2.06\n","Epoch 50/50, Batch 600, Loss: 2.06\n","Epoch 50/50, Batch 700, Loss: 1.98\n"]}]},{"cell_type":"markdown","source":["## Performance Evaluation"],"metadata":{"id":"KIGEpcpbpL5H"}},{"cell_type":"code","source":["# Performance Evaluation\n","def get_accuracy(loader, model):\n","  if loader.dataset.train:\n","    print('Getting accuracy on training data.')\n","  else:\n","    print('Getting accuracy on testing data.')\n","  n_corrects = 0\n","  n_samples = 0\n","  model.eval() # put our model to evaluation mode\n","  with torch.no_grad():\n","    for x,y in loader:\n","      x = x.to(device)\n","      y = y.to(device)\n","      x = x.reshape(x.shape[0], -1)\n","\n","      #forward\n","      scores = model(x) # scores 64 x 10\n","      _, y_pred = scores.max(1)\n","      n_corrects += (y_pred == y).sum()\n","      n_samples += y_pred.size(0)\n","\n","    print(f'We got {n_corrects}/{n_samples} correct. Accuracy = {float(n_corrects)/float(n_samples)* 100.0:.2f}')\n","  model.train() # put our model to train mode again"],"metadata":{"id":"SoTq7zJ6otJ6","executionInfo":{"status":"ok","timestamp":1639293056510,"user_tz":-420,"elapsed":426,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["# Performance Evaluation\n","get_accuracy(train_loader, model)\n","get_accuracy(test_loader, model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7EzJoeZOou-U","executionInfo":{"status":"ok","timestamp":1639293069730,"user_tz":-420,"elapsed":10504,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"outputId":"106ca794-3ff3-4780-8462-0d457e5f02aa"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Getting accuracy on training data.\n","We got 22081/50000 correct. Accuracy = 44.16\n","Getting accuracy on testing data.\n","We got 4203/10000 correct. Accuracy = 42.03\n"]}]},{"cell_type":"markdown","source":["# CIFAR10 using LeNet5 model"],"metadata":{"id":"PttvuTyHmUMh"}},{"cell_type":"markdown","source":["## Import nescessary libraries"],"metadata":{"id":"m5Xf5ESX2mnN"}},{"cell_type":"code","source":["# Import necessary libraries\n","\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.utils.data import DataLoader\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms"],"metadata":{"id":"HWQ9K2uEmasl","executionInfo":{"status":"ok","timestamp":1639293075317,"user_tz":-420,"elapsed":529,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["## Check 'CPU' or 'GPU'"],"metadata":{"id":"MqERTPRd2tkF"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOdj4PIpmaqy","executionInfo":{"status":"ok","timestamp":1639293078236,"user_tz":-420,"elapsed":2,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"outputId":"f5990be5-ad74-49f9-aa82-ed7dedc3e1e1"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["random.seed(1)\n","np.random.seed(1)\n","torch.manual_seed(1)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"],"metadata":{"id":"934g0r-9maho","executionInfo":{"status":"ok","timestamp":1639293081033,"user_tz":-420,"elapsed":423,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["# Hyperparameters\n","\n","n_classes = 10\n","learning_rate = 0.001\n","batch_size = 64\n","n_epochs = 50"],"metadata":{"id":"Xg5jr3xsmago","executionInfo":{"status":"ok","timestamp":1639293085130,"user_tz":-420,"elapsed":500,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["## Prepare CIFAR10 dataset"],"metadata":{"id":"tjQbQHt73Esr"}},{"cell_type":"code","source":["# LOAD data from Google Drive\n","# Load 'CIFAR10' dataset\n","train_dataset = datasets.CIFAR10(root='/content/drive/MyDrive/10. Toán cho KHMT/datasets' , train =True,\n","                              transform=transforms.ToTensor(), download=True)\n","train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,shuffle=True)\n","test_dataset = datasets.CIFAR10(root='/content/drive/MyDrive/10. Toán cho KHMT/datasets' ,train=False,transform=transforms.ToTensor(),\n","                              download=True)\n","test_loader = DataLoader(dataset= test_dataset, batch_size=batch_size, shuffle=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1uKMKHjV2-07","executionInfo":{"status":"ok","timestamp":1639293097865,"user_tz":-420,"elapsed":3498,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"outputId":"24fc6553-c8d4-4fb1-db05-95610ee595c0"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"markdown","source":["## Build LeNet5 model"],"metadata":{"id":"TGnMqGWl3RzE"}},{"cell_type":"code","source":["# Build LeNet5 by using Pytorch\n","class LeNet5(nn.Module):\n","  def __init__(self, n_classes):\n","    super().__init__()\n","    self.model = nn.Sequential(\n","        nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride =1),\n","        nn.Tanh(),\n","        nn.AvgPool2d(kernel_size=2),\n","        nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n","        nn.Tanh(),\n","        nn.AvgPool2d(kernel_size=2),\n","        nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n","        nn.Tanh(),\n","        nn.Flatten(),\n","        nn.Linear(in_features=120, out_features=84),\n","        nn.Tanh(),\n","        nn.Linear(in_features= 84, out_features=n_classes),\n","        nn.Softmax(dim=1)\n","    )\n","  def forward(self, X):\n","    prob = self.model(X)\n","    return prob"],"metadata":{"id":"eNZGI-QJ3UtV","executionInfo":{"status":"ok","timestamp":1639293101719,"user_tz":-420,"elapsed":492,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["model = LeNet5(n_classes=n_classes).to(device)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EMVasOWh3VFa","executionInfo":{"status":"ok","timestamp":1639293105226,"user_tz":-420,"elapsed":533,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"outputId":"c2dbd3bb-7425-4065-cb54-ce20b86b2b91"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["LeNet5(\n","  (model): Sequential(\n","    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): Tanh()\n","    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (4): Tanh()\n","    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (7): Tanh()\n","    (8): Flatten(start_dim=1, end_dim=-1)\n","    (9): Linear(in_features=120, out_features=84, bias=True)\n","    (10): Tanh()\n","    (11): Linear(in_features=84, out_features=10, bias=True)\n","    (12): Softmax(dim=1)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["# Define the loss and the optimization algorithm\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr= learning_rate)"],"metadata":{"id":"V30ZKxVo3YZN","executionInfo":{"status":"ok","timestamp":1639293108373,"user_tz":-420,"elapsed":403,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}}},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":["## Training model"],"metadata":{"id":"deLQ4wCj3fat"}},{"cell_type":"code","source":["#Training model\n","\n","for epoch in range(n_epochs):\n","  for batch_idx, (data, targets) in enumerate(train_loader):\n","\n","    data = data.to(device)\n","    targets = targets.to(device)\n","\n","    scores = model(data)\n","    loss = criterion(scores, targets)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    if(batch_idx+1)% 100 ==0:\n","      print(f'Epoch {epoch+1}/{n_epochs}, Batch {batch_idx+1}, Loss: {loss.item():.2f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8HD6Emfe3dsk","executionInfo":{"status":"ok","timestamp":1639293669374,"user_tz":-420,"elapsed":558003,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"outputId":"23848577-847c-4037-b85b-b71f9256db6b"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50, Batch 100, Loss: 2.18\n","Epoch 1/50, Batch 200, Loss: 2.15\n","Epoch 1/50, Batch 300, Loss: 2.16\n","Epoch 1/50, Batch 400, Loss: 2.06\n","Epoch 1/50, Batch 500, Loss: 2.13\n","Epoch 1/50, Batch 600, Loss: 1.97\n","Epoch 1/50, Batch 700, Loss: 2.13\n","Epoch 2/50, Batch 100, Loss: 2.00\n","Epoch 2/50, Batch 200, Loss: 2.05\n","Epoch 2/50, Batch 300, Loss: 2.14\n","Epoch 2/50, Batch 400, Loss: 2.09\n","Epoch 2/50, Batch 500, Loss: 2.00\n","Epoch 2/50, Batch 600, Loss: 2.15\n","Epoch 2/50, Batch 700, Loss: 2.02\n","Epoch 3/50, Batch 100, Loss: 1.99\n","Epoch 3/50, Batch 200, Loss: 2.02\n","Epoch 3/50, Batch 300, Loss: 1.94\n","Epoch 3/50, Batch 400, Loss: 2.07\n","Epoch 3/50, Batch 500, Loss: 2.12\n","Epoch 3/50, Batch 600, Loss: 2.01\n","Epoch 3/50, Batch 700, Loss: 1.99\n","Epoch 4/50, Batch 100, Loss: 1.99\n","Epoch 4/50, Batch 200, Loss: 2.06\n","Epoch 4/50, Batch 300, Loss: 1.95\n","Epoch 4/50, Batch 400, Loss: 1.97\n","Epoch 4/50, Batch 500, Loss: 2.06\n","Epoch 4/50, Batch 600, Loss: 1.97\n","Epoch 4/50, Batch 700, Loss: 1.93\n","Epoch 5/50, Batch 100, Loss: 2.02\n","Epoch 5/50, Batch 200, Loss: 1.99\n","Epoch 5/50, Batch 300, Loss: 2.08\n","Epoch 5/50, Batch 400, Loss: 2.01\n","Epoch 5/50, Batch 500, Loss: 1.97\n","Epoch 5/50, Batch 600, Loss: 1.97\n","Epoch 5/50, Batch 700, Loss: 2.00\n","Epoch 6/50, Batch 100, Loss: 1.98\n","Epoch 6/50, Batch 200, Loss: 2.05\n","Epoch 6/50, Batch 300, Loss: 2.07\n","Epoch 6/50, Batch 400, Loss: 1.93\n","Epoch 6/50, Batch 500, Loss: 1.92\n","Epoch 6/50, Batch 600, Loss: 2.02\n","Epoch 6/50, Batch 700, Loss: 1.85\n","Epoch 7/50, Batch 100, Loss: 2.01\n","Epoch 7/50, Batch 200, Loss: 2.00\n","Epoch 7/50, Batch 300, Loss: 1.95\n","Epoch 7/50, Batch 400, Loss: 2.05\n","Epoch 7/50, Batch 500, Loss: 1.92\n","Epoch 7/50, Batch 600, Loss: 2.05\n","Epoch 7/50, Batch 700, Loss: 1.97\n","Epoch 8/50, Batch 100, Loss: 2.05\n","Epoch 8/50, Batch 200, Loss: 1.98\n","Epoch 8/50, Batch 300, Loss: 2.05\n","Epoch 8/50, Batch 400, Loss: 2.04\n","Epoch 8/50, Batch 500, Loss: 1.88\n","Epoch 8/50, Batch 600, Loss: 2.02\n","Epoch 8/50, Batch 700, Loss: 1.99\n","Epoch 9/50, Batch 100, Loss: 1.90\n","Epoch 9/50, Batch 200, Loss: 1.87\n","Epoch 9/50, Batch 300, Loss: 1.84\n","Epoch 9/50, Batch 400, Loss: 1.98\n","Epoch 9/50, Batch 500, Loss: 1.97\n","Epoch 9/50, Batch 600, Loss: 1.90\n","Epoch 9/50, Batch 700, Loss: 1.91\n","Epoch 10/50, Batch 100, Loss: 1.90\n","Epoch 10/50, Batch 200, Loss: 1.90\n","Epoch 10/50, Batch 300, Loss: 1.95\n","Epoch 10/50, Batch 400, Loss: 1.94\n","Epoch 10/50, Batch 500, Loss: 1.97\n","Epoch 10/50, Batch 600, Loss: 1.96\n","Epoch 10/50, Batch 700, Loss: 1.94\n","Epoch 11/50, Batch 100, Loss: 1.93\n","Epoch 11/50, Batch 200, Loss: 1.89\n","Epoch 11/50, Batch 300, Loss: 1.99\n","Epoch 11/50, Batch 400, Loss: 1.92\n","Epoch 11/50, Batch 500, Loss: 1.85\n","Epoch 11/50, Batch 600, Loss: 1.91\n","Epoch 11/50, Batch 700, Loss: 1.94\n","Epoch 12/50, Batch 100, Loss: 1.82\n","Epoch 12/50, Batch 200, Loss: 2.02\n","Epoch 12/50, Batch 300, Loss: 1.90\n","Epoch 12/50, Batch 400, Loss: 1.87\n","Epoch 12/50, Batch 500, Loss: 1.89\n","Epoch 12/50, Batch 600, Loss: 2.04\n","Epoch 12/50, Batch 700, Loss: 1.96\n","Epoch 13/50, Batch 100, Loss: 1.86\n","Epoch 13/50, Batch 200, Loss: 1.88\n","Epoch 13/50, Batch 300, Loss: 1.95\n","Epoch 13/50, Batch 400, Loss: 1.98\n","Epoch 13/50, Batch 500, Loss: 1.97\n","Epoch 13/50, Batch 600, Loss: 1.88\n","Epoch 13/50, Batch 700, Loss: 1.85\n","Epoch 14/50, Batch 100, Loss: 1.88\n","Epoch 14/50, Batch 200, Loss: 1.97\n","Epoch 14/50, Batch 300, Loss: 1.96\n","Epoch 14/50, Batch 400, Loss: 1.92\n","Epoch 14/50, Batch 500, Loss: 1.90\n","Epoch 14/50, Batch 600, Loss: 1.90\n","Epoch 14/50, Batch 700, Loss: 1.94\n","Epoch 15/50, Batch 100, Loss: 1.83\n","Epoch 15/50, Batch 200, Loss: 1.81\n","Epoch 15/50, Batch 300, Loss: 1.89\n","Epoch 15/50, Batch 400, Loss: 1.94\n","Epoch 15/50, Batch 500, Loss: 1.90\n","Epoch 15/50, Batch 600, Loss: 1.92\n","Epoch 15/50, Batch 700, Loss: 1.92\n","Epoch 16/50, Batch 100, Loss: 1.84\n","Epoch 16/50, Batch 200, Loss: 1.84\n","Epoch 16/50, Batch 300, Loss: 1.91\n","Epoch 16/50, Batch 400, Loss: 1.81\n","Epoch 16/50, Batch 500, Loss: 1.84\n","Epoch 16/50, Batch 600, Loss: 1.77\n","Epoch 16/50, Batch 700, Loss: 1.83\n","Epoch 17/50, Batch 100, Loss: 1.79\n","Epoch 17/50, Batch 200, Loss: 1.82\n","Epoch 17/50, Batch 300, Loss: 1.95\n","Epoch 17/50, Batch 400, Loss: 1.78\n","Epoch 17/50, Batch 500, Loss: 1.87\n","Epoch 17/50, Batch 600, Loss: 2.00\n","Epoch 17/50, Batch 700, Loss: 1.88\n","Epoch 18/50, Batch 100, Loss: 1.82\n","Epoch 18/50, Batch 200, Loss: 1.84\n","Epoch 18/50, Batch 300, Loss: 1.87\n","Epoch 18/50, Batch 400, Loss: 1.83\n","Epoch 18/50, Batch 500, Loss: 1.80\n","Epoch 18/50, Batch 600, Loss: 1.88\n","Epoch 18/50, Batch 700, Loss: 1.81\n","Epoch 19/50, Batch 100, Loss: 1.78\n","Epoch 19/50, Batch 200, Loss: 1.84\n","Epoch 19/50, Batch 300, Loss: 1.84\n","Epoch 19/50, Batch 400, Loss: 1.83\n","Epoch 19/50, Batch 500, Loss: 1.76\n","Epoch 19/50, Batch 600, Loss: 1.91\n","Epoch 19/50, Batch 700, Loss: 1.82\n","Epoch 20/50, Batch 100, Loss: 1.80\n","Epoch 20/50, Batch 200, Loss: 1.82\n","Epoch 20/50, Batch 300, Loss: 1.85\n","Epoch 20/50, Batch 400, Loss: 1.89\n","Epoch 20/50, Batch 500, Loss: 1.92\n","Epoch 20/50, Batch 600, Loss: 1.84\n","Epoch 20/50, Batch 700, Loss: 1.88\n","Epoch 21/50, Batch 100, Loss: 1.71\n","Epoch 21/50, Batch 200, Loss: 1.91\n","Epoch 21/50, Batch 300, Loss: 1.86\n","Epoch 21/50, Batch 400, Loss: 1.78\n","Epoch 21/50, Batch 500, Loss: 1.86\n","Epoch 21/50, Batch 600, Loss: 1.87\n","Epoch 21/50, Batch 700, Loss: 1.86\n","Epoch 22/50, Batch 100, Loss: 1.91\n","Epoch 22/50, Batch 200, Loss: 1.80\n","Epoch 22/50, Batch 300, Loss: 1.96\n","Epoch 22/50, Batch 400, Loss: 1.91\n","Epoch 22/50, Batch 500, Loss: 1.88\n","Epoch 22/50, Batch 600, Loss: 1.84\n","Epoch 22/50, Batch 700, Loss: 1.87\n","Epoch 23/50, Batch 100, Loss: 1.77\n","Epoch 23/50, Batch 200, Loss: 1.83\n","Epoch 23/50, Batch 300, Loss: 1.96\n","Epoch 23/50, Batch 400, Loss: 1.93\n","Epoch 23/50, Batch 500, Loss: 1.77\n","Epoch 23/50, Batch 600, Loss: 1.86\n","Epoch 23/50, Batch 700, Loss: 1.85\n","Epoch 24/50, Batch 100, Loss: 1.77\n","Epoch 24/50, Batch 200, Loss: 1.88\n","Epoch 24/50, Batch 300, Loss: 1.77\n","Epoch 24/50, Batch 400, Loss: 1.86\n","Epoch 24/50, Batch 500, Loss: 1.94\n","Epoch 24/50, Batch 600, Loss: 1.82\n","Epoch 24/50, Batch 700, Loss: 1.83\n","Epoch 25/50, Batch 100, Loss: 1.82\n","Epoch 25/50, Batch 200, Loss: 1.89\n","Epoch 25/50, Batch 300, Loss: 1.82\n","Epoch 25/50, Batch 400, Loss: 1.67\n","Epoch 25/50, Batch 500, Loss: 1.86\n","Epoch 25/50, Batch 600, Loss: 1.74\n","Epoch 25/50, Batch 700, Loss: 1.87\n","Epoch 26/50, Batch 100, Loss: 1.78\n","Epoch 26/50, Batch 200, Loss: 1.76\n","Epoch 26/50, Batch 300, Loss: 1.80\n","Epoch 26/50, Batch 400, Loss: 1.78\n","Epoch 26/50, Batch 500, Loss: 1.81\n","Epoch 26/50, Batch 600, Loss: 1.83\n","Epoch 26/50, Batch 700, Loss: 1.78\n","Epoch 27/50, Batch 100, Loss: 1.81\n","Epoch 27/50, Batch 200, Loss: 1.84\n","Epoch 27/50, Batch 300, Loss: 1.84\n","Epoch 27/50, Batch 400, Loss: 1.88\n","Epoch 27/50, Batch 500, Loss: 1.74\n","Epoch 27/50, Batch 600, Loss: 1.78\n","Epoch 27/50, Batch 700, Loss: 1.83\n","Epoch 28/50, Batch 100, Loss: 1.78\n","Epoch 28/50, Batch 200, Loss: 1.77\n","Epoch 28/50, Batch 300, Loss: 1.87\n","Epoch 28/50, Batch 400, Loss: 1.80\n","Epoch 28/50, Batch 500, Loss: 1.83\n","Epoch 28/50, Batch 600, Loss: 1.85\n","Epoch 28/50, Batch 700, Loss: 1.68\n","Epoch 29/50, Batch 100, Loss: 1.76\n","Epoch 29/50, Batch 200, Loss: 1.78\n","Epoch 29/50, Batch 300, Loss: 1.87\n","Epoch 29/50, Batch 400, Loss: 1.82\n","Epoch 29/50, Batch 500, Loss: 1.78\n","Epoch 29/50, Batch 600, Loss: 1.82\n","Epoch 29/50, Batch 700, Loss: 1.84\n","Epoch 30/50, Batch 100, Loss: 1.82\n","Epoch 30/50, Batch 200, Loss: 1.75\n","Epoch 30/50, Batch 300, Loss: 1.73\n","Epoch 30/50, Batch 400, Loss: 1.79\n","Epoch 30/50, Batch 500, Loss: 1.81\n","Epoch 30/50, Batch 600, Loss: 1.76\n","Epoch 30/50, Batch 700, Loss: 1.81\n","Epoch 31/50, Batch 100, Loss: 1.76\n","Epoch 31/50, Batch 200, Loss: 1.73\n","Epoch 31/50, Batch 300, Loss: 1.81\n","Epoch 31/50, Batch 400, Loss: 1.82\n","Epoch 31/50, Batch 500, Loss: 1.84\n","Epoch 31/50, Batch 600, Loss: 1.78\n","Epoch 31/50, Batch 700, Loss: 1.89\n","Epoch 32/50, Batch 100, Loss: 1.72\n","Epoch 32/50, Batch 200, Loss: 1.88\n","Epoch 32/50, Batch 300, Loss: 1.80\n","Epoch 32/50, Batch 400, Loss: 1.82\n","Epoch 32/50, Batch 500, Loss: 1.81\n","Epoch 32/50, Batch 600, Loss: 1.70\n","Epoch 32/50, Batch 700, Loss: 1.80\n","Epoch 33/50, Batch 100, Loss: 1.76\n","Epoch 33/50, Batch 200, Loss: 1.87\n","Epoch 33/50, Batch 300, Loss: 1.72\n","Epoch 33/50, Batch 400, Loss: 1.82\n","Epoch 33/50, Batch 500, Loss: 1.82\n","Epoch 33/50, Batch 600, Loss: 1.69\n","Epoch 33/50, Batch 700, Loss: 1.76\n","Epoch 34/50, Batch 100, Loss: 1.72\n","Epoch 34/50, Batch 200, Loss: 1.82\n","Epoch 34/50, Batch 300, Loss: 1.85\n","Epoch 34/50, Batch 400, Loss: 1.78\n","Epoch 34/50, Batch 500, Loss: 1.70\n","Epoch 34/50, Batch 600, Loss: 1.89\n","Epoch 34/50, Batch 700, Loss: 1.88\n","Epoch 35/50, Batch 100, Loss: 1.71\n","Epoch 35/50, Batch 200, Loss: 1.75\n","Epoch 35/50, Batch 300, Loss: 1.84\n","Epoch 35/50, Batch 400, Loss: 1.85\n","Epoch 35/50, Batch 500, Loss: 1.75\n","Epoch 35/50, Batch 600, Loss: 1.74\n","Epoch 35/50, Batch 700, Loss: 1.82\n","Epoch 36/50, Batch 100, Loss: 1.74\n","Epoch 36/50, Batch 200, Loss: 1.68\n","Epoch 36/50, Batch 300, Loss: 1.77\n","Epoch 36/50, Batch 400, Loss: 1.74\n","Epoch 36/50, Batch 500, Loss: 1.85\n","Epoch 36/50, Batch 600, Loss: 1.76\n","Epoch 36/50, Batch 700, Loss: 1.70\n","Epoch 37/50, Batch 100, Loss: 1.89\n","Epoch 37/50, Batch 200, Loss: 1.72\n","Epoch 37/50, Batch 300, Loss: 1.77\n","Epoch 37/50, Batch 400, Loss: 1.77\n","Epoch 37/50, Batch 500, Loss: 1.90\n","Epoch 37/50, Batch 600, Loss: 1.72\n","Epoch 37/50, Batch 700, Loss: 1.77\n","Epoch 38/50, Batch 100, Loss: 1.92\n","Epoch 38/50, Batch 200, Loss: 1.62\n","Epoch 38/50, Batch 300, Loss: 1.78\n","Epoch 38/50, Batch 400, Loss: 1.87\n","Epoch 38/50, Batch 500, Loss: 1.74\n","Epoch 38/50, Batch 600, Loss: 1.74\n","Epoch 38/50, Batch 700, Loss: 1.76\n","Epoch 39/50, Batch 100, Loss: 1.78\n","Epoch 39/50, Batch 200, Loss: 1.76\n","Epoch 39/50, Batch 300, Loss: 1.73\n","Epoch 39/50, Batch 400, Loss: 1.75\n","Epoch 39/50, Batch 500, Loss: 1.74\n","Epoch 39/50, Batch 600, Loss: 1.77\n","Epoch 39/50, Batch 700, Loss: 1.79\n","Epoch 40/50, Batch 100, Loss: 1.79\n","Epoch 40/50, Batch 200, Loss: 1.72\n","Epoch 40/50, Batch 300, Loss: 1.77\n","Epoch 40/50, Batch 400, Loss: 1.72\n","Epoch 40/50, Batch 500, Loss: 1.73\n","Epoch 40/50, Batch 600, Loss: 1.89\n","Epoch 40/50, Batch 700, Loss: 1.70\n","Epoch 41/50, Batch 100, Loss: 1.75\n","Epoch 41/50, Batch 200, Loss: 1.80\n","Epoch 41/50, Batch 300, Loss: 1.80\n","Epoch 41/50, Batch 400, Loss: 1.76\n","Epoch 41/50, Batch 500, Loss: 1.82\n","Epoch 41/50, Batch 600, Loss: 1.82\n","Epoch 41/50, Batch 700, Loss: 1.74\n","Epoch 42/50, Batch 100, Loss: 1.69\n","Epoch 42/50, Batch 200, Loss: 1.73\n","Epoch 42/50, Batch 300, Loss: 1.71\n","Epoch 42/50, Batch 400, Loss: 1.76\n","Epoch 42/50, Batch 500, Loss: 1.74\n","Epoch 42/50, Batch 600, Loss: 1.76\n","Epoch 42/50, Batch 700, Loss: 1.62\n","Epoch 43/50, Batch 100, Loss: 1.71\n","Epoch 43/50, Batch 200, Loss: 1.77\n","Epoch 43/50, Batch 300, Loss: 1.81\n","Epoch 43/50, Batch 400, Loss: 1.70\n","Epoch 43/50, Batch 500, Loss: 1.70\n","Epoch 43/50, Batch 600, Loss: 1.85\n","Epoch 43/50, Batch 700, Loss: 1.74\n","Epoch 44/50, Batch 100, Loss: 1.71\n","Epoch 44/50, Batch 200, Loss: 1.74\n","Epoch 44/50, Batch 300, Loss: 1.71\n","Epoch 44/50, Batch 400, Loss: 1.73\n","Epoch 44/50, Batch 500, Loss: 1.73\n","Epoch 44/50, Batch 600, Loss: 1.75\n","Epoch 44/50, Batch 700, Loss: 1.86\n","Epoch 45/50, Batch 100, Loss: 1.82\n","Epoch 45/50, Batch 200, Loss: 1.70\n","Epoch 45/50, Batch 300, Loss: 1.74\n","Epoch 45/50, Batch 400, Loss: 1.75\n","Epoch 45/50, Batch 500, Loss: 1.74\n","Epoch 45/50, Batch 600, Loss: 1.72\n","Epoch 45/50, Batch 700, Loss: 1.78\n","Epoch 46/50, Batch 100, Loss: 1.73\n","Epoch 46/50, Batch 200, Loss: 1.69\n","Epoch 46/50, Batch 300, Loss: 1.64\n","Epoch 46/50, Batch 400, Loss: 1.73\n","Epoch 46/50, Batch 500, Loss: 1.76\n","Epoch 46/50, Batch 600, Loss: 1.61\n","Epoch 46/50, Batch 700, Loss: 1.69\n","Epoch 47/50, Batch 100, Loss: 1.67\n","Epoch 47/50, Batch 200, Loss: 1.82\n","Epoch 47/50, Batch 300, Loss: 1.76\n","Epoch 47/50, Batch 400, Loss: 1.73\n","Epoch 47/50, Batch 500, Loss: 1.69\n","Epoch 47/50, Batch 600, Loss: 1.75\n","Epoch 47/50, Batch 700, Loss: 1.76\n","Epoch 48/50, Batch 100, Loss: 1.76\n","Epoch 48/50, Batch 200, Loss: 1.83\n","Epoch 48/50, Batch 300, Loss: 1.81\n","Epoch 48/50, Batch 400, Loss: 1.76\n","Epoch 48/50, Batch 500, Loss: 1.70\n","Epoch 48/50, Batch 600, Loss: 1.72\n","Epoch 48/50, Batch 700, Loss: 1.70\n","Epoch 49/50, Batch 100, Loss: 1.80\n","Epoch 49/50, Batch 200, Loss: 1.79\n","Epoch 49/50, Batch 300, Loss: 1.75\n","Epoch 49/50, Batch 400, Loss: 1.69\n","Epoch 49/50, Batch 500, Loss: 1.72\n","Epoch 49/50, Batch 600, Loss: 1.71\n","Epoch 49/50, Batch 700, Loss: 1.75\n","Epoch 50/50, Batch 100, Loss: 1.70\n","Epoch 50/50, Batch 200, Loss: 1.88\n","Epoch 50/50, Batch 300, Loss: 1.70\n","Epoch 50/50, Batch 400, Loss: 1.67\n","Epoch 50/50, Batch 500, Loss: 1.77\n","Epoch 50/50, Batch 600, Loss: 1.71\n","Epoch 50/50, Batch 700, Loss: 1.78\n"]}]},{"cell_type":"markdown","source":["## Performance Evaluation"],"metadata":{"id":"E7S52shH3kux"}},{"cell_type":"code","source":["def get_accracy(loader, model):\n","  if loader.dataset.train:\n","    print('Getting accuracy on training data.')\n","  else:\n","    print('Getting accuracy on testing data.')\n","  \n","  n_corrects = 0\n","  n_samples = 0\n","  model.eval()\n","\n","  with torch.no_grad():\n","    for x,y in loader:\n","      x = x.to(device)\n","      y = y.to(device)\n","\n","      scores = model(x)\n","      _,y_pred = scores.max(1)\n","      n_corrects += (y_pred == y).sum()\n","      n_samples += y_pred.size(0)\n","\n","    print(f'We got {n_corrects}/{n_samples} correct. Accuracy = {float(n_corrects)/float(n_samples)* 100.0:.2f}')\n","  model.train()"],"metadata":{"id":"tq03cd8S3dUa","executionInfo":{"status":"ok","timestamp":1639293710815,"user_tz":-420,"elapsed":522,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["get_accracy(train_loader,model)\n","get_accracy(test_loader, model)"],"metadata":{"id":"nS4iAPuQ3qNT","executionInfo":{"status":"ok","timestamp":1639293724703,"user_tz":-420,"elapsed":10985,"user":{"displayName":"Trường Nguyễn Nhật","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtWdI3oyShRdUZ_ZqjaxJ617ug-HyWq6_RBGw0=s64","userId":"00258690871686345275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"60f79ea5-6b8e-47a3-e52a-636bd8df20ca"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Getting accuracy on training data.\n","We got 36548/50000 correct. Accuracy = 73.10\n","Getting accuracy on testing data.\n","We got 5284/10000 correct. Accuracy = 52.84\n"]}]}]}